"""
Created on Fri May 11 18:25:48 2018 
CALIBRATION - TEST PULSES
@author: Gabriel Blaj

2020-12-03 - Mikhail Dubrovin - begin conversion to LCLS2
"""
import os
import sys
from time import time
import logging
logger = logging.getLogger(__name__)
DICT_NAME_TO_LEVEL = logging._nameToLevel
#print('DICT_NAME_TO_LEVEL:',DICT_NAME_TO_LEVEL)
#{'CRITICAL': 50, 'FATAL': 50, 'ERROR': 40, 'WARN': 30, 'WARNING': 30, 'INFO': 20, 'DEBUG': 10, 'NOTSET': 0}

import numpy as np

import json
from psana import DataSource
from psana.detector.UtilsEpix import CALIB_REPO_EPIX10KA, FNAME_PANEL_ID_ALIASES, alias_for_id
from psana.pyalgos.generic.Utils import log_rec_on_start, str_tstamp, create_directory, save_textfile, set_file_access_mode
from psana.pyalgos.generic.NDArrUtils import info_ndarr, divide_protected
import psana.detector.UtilsEpix10ka as ue

#----

def save_log_record_on_start(dirrepo, procname, fac_mode=0o777, tsfmt='%Y-%m-%dT%H:%M:%S%z'):
    """Adds record on start to the log file <dirrepo>/logs/log-<procname>-<year>.txt
    """
    rec = log_rec_on_start(tsfmt)
    year = str_tstamp(fmt='%Y')
    create_directory(dirrepo, fac_mode)
    dirlog = '%s/logs' % dirrepo
    create_directory(dirlog, fac_mode)
    logfname = '%s/log_%s_%s.txt' % (dirlog, procname, year)

    fexists = os.path.exists(logfname)
    save_textfile(rec, logfname, mode='a')
    if not fexists: set_file_access_mode(logfname, fac_mode)

    logger.debug('Record on start: %s' % rec)
    logger.info('Saved: %s' % logfname)


def save_2darray_in_textfile(nda, fname, fmode, fmt):
    fexists = os.path.exists(fname)
    np.savetxt(fname, nda, fmt=fmt)
    if not fexists: set_file_access_mode(fname, fmode)
    logger.info('saved:  %s' % fname)


def save_ndarray_in_textfile(nda, fname, fmode, fmt):
    fexists = os.path.exists(fname)
    save_txt(fname=fname, arr=nda, fmt=fmt)
    if not fexists: set_file_access_mode(fname, fmode)
    logger.debug('saved: %s fmode: %s fmt: %s' % (fname, oct(fmode), fmt))


def find_file_for_timestamp(dirname, pattern, tstamp):
    # list of file names in directory, dirname, containing pattern
    fnames = [name for name in os.listdir(dirname) if os.path.splitext(name)[-1]=='.dat' and pattern in name]

    # list of int tstamps 
    # !!! here we assume specific name structure generated by file_name_prefix
    itstamps = [int(name.split('_',3)[2]) for name in fnames]

    # reverse-sort int timestamps in the list
    itstamps.sort(key=int,reverse=True)

    # find the nearest to requested timestamp
    for its in itstamps:
        if its <= int(tstamp):
            # find and return the full file name for selected timestamp
            ts = str(its)

            for name in fnames:
                if ts in name: 
                     fname = '%s/%s' % (dirname, name)
                     logger.info('  selected %s for %s and %s' % (os.path.basename(fname),pattern,tstamp))
                     return fname

    logger.warning('directory %s\n         DOES NOT CONTAIN file for pattern %s and timestamp <= %s'%\
                   (dirname,pattern,tstamp))
    return None


def load_panel_constants(dir_ctype, pattern, tstamp):
    fname = find_file_for_timestamp(dir_ctype, pattern, tstamp)
    arr=None
    if fname is not None and os.path.exists(fname):
        arr=np.loadtxt(fname)
        logger.info('Loaded: %s' % fname)
    else:
        logger.warning('file DOES NOT EXIST: %s' % fname)
        logger.warning('DO NOT save save constants for missing files')
    return arr


def dir_merge(dirrepo):
    return '%s/merge_tmp' % dirrepo


def fname_prefix_merge(dmerge, detname, tstamp, exp, irun):
    return '%s/%s-%s-%s-r%04d' % (dmerge, detname, tstamp, exp, irun)


def dir_names(dirrepo, panel_id):
    """Defines structure of subdirectories in calibration repository.
    """
    dir_panel  = '%s/%s' % (dirrepo, panel_id)
    dir_offset = '%s/offset'    % dir_panel
    dir_peds   = '%s/pedestals' % dir_panel
    dir_plots  = '%s/plots'     % dir_panel
    dir_work   = '%s/work'      % dir_panel
    dir_gain   = '%s/gain'      % dir_panel
    dir_rms    = '%s/rms'       % dir_panel
    dir_status = '%s/status'    % dir_panel
    return dir_panel, dir_offset, dir_peds, dir_plots, dir_work, dir_gain, dir_rms, dir_status


def path_prefixes(fname_prefix, dir_offset, dir_peds, dir_plots, dir_gain, dir_rms, dir_status):
    prefix_offset= '%s/%s' % (dir_offset, fname_prefix)
    prefix_peds  = '%s/%s' % (dir_peds,   fname_prefix)
    prefix_plots = '%s/%s' % (dir_plots,  fname_prefix)
    prefix_gain  = '%s/%s' % (dir_gain,   fname_prefix)
    prefix_rms   = '%s/%s' % (dir_rms,    fname_prefix)
    prefix_status= '%s/%s' % (dir_status, fname_prefix)
    return prefix_offset, prefix_peds, prefix_plots, prefix_gain, prefix_rms, prefix_status


def file_name_prefix(dirrepo, panel_id, tstamp, exp, irun):
    panel_alias = alias_for_id(panel_id, fname=os.path.join(dirrepo, FNAME_PANEL_ID_ALIASES))
    return 'epix10ka_%s_%s_%s_r%04d' % (panel_alias, tstamp, exp, irun), panel_alias


def tstamps_run_and_now(trun_sec): # unix epoch time, e.g. 1607569818.532117 sec
    """Returns (str) tstamp_run, tstamp_now#, e.g. (str) 20201209191018, 20201217140026
    """
    ts_run = str_tstamp(fmt='%Y%m%d%H%M%S', time_sec=trun_sec)
    ts_now = str_tstamp(fmt='%Y%m%d%H%M%S', time_sec=None)
    return ts_run, ts_now


def step_counter(metadata, nstep_tot, nstep_run, stype='pedestal', nspace=None):
    #nspace=7 - for 103 charge injection calib-cycles, =None for 5 dark
    logger.info('step_counter metadata:%s nstep_tot:%d nstep_run:%d stype:%s nspace:%s'%\
                              (metadata, nstep_tot, nstep_run,stype, str(nspace)))
    if not metadata:
        logger.warning('STEP METADATA IS NOT AVAILABLE nstep_tot:%d, nstep_run:%d' % (nstep_tot, nstep_run))
        return nstep_tot

    assert isinstance(metadata, dict), 'UNEXPECTED non-dict DATA TYPE FOR METADATA: %s'%str(type(metadata))

    scantype = metadata['scantype']
    stepnum = metadata['step']

    if scantype != stype:
        logger.warning('UNEXPECTED SCAN TYPE %s' % scantype)
        return None

    # LCLS1
    #step_names = STEP_NAMES_DARK if nspace is None else step_names(nspace)
    #ind = step_names.index(step_value)
    #if ind in list_of_step_collected():
    #    logger.warning('CALIB-CYCLE %d: %s HAS ALREADY BEEN PROCESSED. SKIPPING' % (ind, step_value))
    #    return None

    if stepnum != nstep_tot:
        s = 'SEQUENTIAL STEP NUMBER nstep_tot:%d, nstep_run:%d' % (nstep_tot, nstep_run)
        s += ' IS NOT CONSISTENT WITH METADATA %s %d' % (scantype, stepnum)
        logger.warning(s)

    return stepnum


def mean_constrained(arr, lo, hi):
    """Evaluates mean value of the input array for values between low and high limits
    """
    condlist = (np.logical_not(np.logical_or(arr<lo, arr>hi)),)
    arr1 = np.ones(arr.shape, dtype=np.int32)
    arr_of1 = np.select(condlist, (arr1,), 0)
    arr_ofv = np.select(condlist, (arr,), 0)
    ngood = arr_of1.sum()
    return arr_ofv.sum()/ngood if ngood else None


def evaluate_limits(arr, nneg=5, npos=5, lim_lo=1, lim_hi=16000, cmt=''):
    """Evaluates low and high limit of the array, which are used to find bad pixels.
    """
    ave, std = (arr.mean(), arr.std()) if (nneg>0 or npos>0) else (None,None)
    lo = ave-nneg*std if nneg>0 else lim_lo
    hi = ave+npos*std if npos>0 else lim_hi
    lo, hi = max(lo, lim_lo), min(hi, lim_hi)

    logger.debug('  %s: %s ave, std = %.3f, %.3f  low, high limits = %.3f, %.3f'%\
                 (sys._getframe().f_code.co_name, cmt, ave, std, lo, hi))

    return lo, hi


def proc_dark_block(block, **opts):
    """Returns per-panel (352, 384) arrays of mean, rms, ...
       block.shape = (nrecs, 352, 384), where nrecs <= 1024
    """
    exp        = opts.get('exp', None)
    detname    = opts.get('det', None)

    int_lo     = opts.get('int_lo', 1)       # lowest  intensity accepted for dark evaluation
    int_hi     = opts.get('int_hi', 16000)   # highest intensity accepted for dark evaluation
    intnlo     = opts.get('intnlo', 6.0)     # intensity ditribution number-of-sigmas low
    intnhi     = opts.get('intnhi', 6.0)     # intensity ditribution number-of-sigmas high
                                 
    rms_lo     = opts.get('rms_lo', 0.001)   # rms ditribution low
    rms_hi     = opts.get('rms_hi', 16000)   # rms ditribution high
    rmsnlo     = opts.get('rmsnlo', 6.0)     # rms ditribution number-of-sigmas low
    rmsnhi     = opts.get('rmsnhi', 6.0)     # rms ditribution number-of-sigmas high

    fraclm     = opts.get('fraclm', 0.1)     # allowed fraction limit
    nsigma     = opts.get('nsigma', 6.0)     # number of sigmas for gated eveluation

    blockdbl = np.array(block, dtype=np.double)

    logger.debug('in proc_dark_block for exp=%s det=%s, block.shape=%s' % (exp, detname, str(block.shape)))
    nrecs, ny, nx = block.shape
    shape = (ny, nx)

    arr0       = np.zeros(shape, dtype=np.int64)
    arr1       = np.ones (shape, dtype=np.int64)

    arr_sum0   = np.zeros(shape, dtype=np.int64)
    arr_sum1   = np.zeros(shape, dtype=np.double)
    arr_sum2   = np.zeros(shape, dtype=np.double)

    gate_lo    = arr1 * int_lo
    gate_hi    = arr1 * int_hi

    t0_sec = time()

    # 1st loop over recs(non-empty events) in block
    for nrec in range(min(nrecs,500)):
        raw    = block[nrec,:]
        rawdbl = blockdbl[nrec,:]

        cond_lo = raw<gate_lo
        cond_hi = raw>gate_hi
        condlist = (np.logical_not(np.logical_or(cond_lo, cond_hi)),)

        arr_sum0 += np.select(condlist, (arr1,), 0)
        arr_sum1 += np.select(condlist, (rawdbl,), 0)
        arr_sum2 += np.select(condlist, (np.square(rawdbl),), 0)

    arr_av1 = divide_protected(arr_sum1, arr_sum0)
    arr_av2 = divide_protected(arr_sum2, arr_sum0)

    arr_rms = np.sqrt(arr_av2 - np.square(arr_av1))

    #rms_ave = arr_rms.mean()
    rms_ave = mean_constrained(arr_rms, rms_lo, rms_hi)

    logger.debug(info_ndarr(arr_av1, '1st loop proc time = %.3f sec arr_av1' % (time()-t0_sec)))
    gate_half = nsigma*rms_ave
    logger.debug('set gate_half=%.3f for intensity gated average, which is %.3f * sigma' % (gate_half,nsigma))

    # 2nd loop over recs in block to evaluate gated parameters

    sta_int_lo = np.zeros(shape, dtype=np.int64)
    sta_int_hi = np.zeros(shape, dtype=np.int64)

    arr_max = np.zeros(shape, dtype=block.dtype)
    arr_min = np.ones (shape, dtype=block.dtype) * 0x3ffff

    gate_hi = np.minimum(arr_av1 + gate_half, gate_hi).astype(dtype=raw.dtype)
    gate_lo = np.maximum(arr_av1 - gate_half, gate_lo).astype(dtype=raw.dtype)

    arr_sum0 = np.zeros(shape, dtype=np.int64)
    arr_sum1 = np.zeros(shape, dtype=np.double)
    arr_sum2 = np.zeros(shape, dtype=np.double)

    for nrec in range(nrecs):
        raw    = block[nrec,:]
        rawdbl = blockdbl[nrec,:]

        cond_lo = raw<gate_lo
        cond_hi = raw>gate_hi
        condlist = (np.logical_not(np.logical_or(cond_lo, cond_hi)),)

        arr_sum0 += np.select(condlist, (arr1,), 0)
        arr_sum1 += np.select(condlist, (rawdbl,), 0)
        arr_sum2 += np.select(condlist, (np.square(rawdbl),), 0)

        sta_int_lo += np.select((raw<int_lo,), (arr1,), 0)
        sta_int_hi += np.select((raw>int_hi,), (arr1,), 0)

        arr_max = np.maximum(arr_max, raw)
        arr_min = np.minimum(arr_min, raw)

    arr_av1 = divide_protected(arr_sum1, arr_sum0)
    arr_av2 = divide_protected(arr_sum2, arr_sum0)

    frac_int_lo = np.array(sta_int_lo/nrecs, dtype=np.float32)
    frac_int_hi = np.array(sta_int_hi/nrecs, dtype=np.float32)

    arr_rms = np.sqrt(arr_av2 - np.square(arr_av1))
    #rms_ave = arr_rms.mean()
    rms_ave = mean_constrained(arr_rms, rms_lo, rms_hi)
 
    rms_min, rms_max = evaluate_limits(arr_rms, rmsnlo, rmsnhi, rms_lo, rms_hi, cmt='RMS')
    ave_min, ave_max = evaluate_limits(arr_av1, intnlo, intnhi, int_lo, int_hi, cmt='AVE')

    arr_sta_rms_hi = np.select((arr_rms>rms_max,),    (arr1,), 0)
    arr_sta_rms_lo = np.select((arr_rms<rms_min,),    (arr1,), 0)
    arr_sta_int_hi = np.select((frac_int_hi>fraclm,), (arr1,), 0)
    arr_sta_int_lo = np.select((frac_int_lo>fraclm,), (arr1,), 0)
    arr_sta_ave_hi = np.select((arr_av1>ave_max,),    (arr1,), 0)
    arr_sta_ave_lo = np.select((arr_av1<ave_min,),    (arr1,), 0)

    logger.info('Bad pixel status:'\
               +'\n  status  1: %8d pixel rms       > %.3f' % (arr_sta_rms_hi.sum(), rms_max)\
               +'\n  status  8: %8d pixel rms       < %.3f' % (arr_sta_rms_lo.sum(), rms_min)\
               +'\n  status  2: %8d pixel intensity > %g in more than %g fraction of events' % (arr_sta_int_hi.sum(), int_hi, fraclm)\
               +'\n  status  4: %8d pixel intensity < %g in more than %g fraction of events' % (arr_sta_int_lo.sum(), int_lo, fraclm)\
               +'\n  status 16: %8d pixel average   > %g'   % (arr_sta_ave_hi.sum(), ave_max)\
               +'\n  status 32: %8d pixel average   < %g'   % (arr_sta_ave_lo.sum(), ave_min)\
               )

    #0/1/2/4/8/16/32 for good/hot-rms/saturated/cold/cold-rms/average above limit/average below limit, 
    arr_sta = np.zeros(shape, dtype=np.int64)
    arr_sta += arr_sta_rms_hi    # hot rms
    arr_sta += arr_sta_rms_lo*8  # cold rms
    arr_sta += arr_sta_int_hi*2  # satturated
    arr_sta += arr_sta_int_lo*4  # cold
    arr_sta += arr_sta_ave_hi*16 # too large average
    arr_sta += arr_sta_ave_lo*32 # too small average
    
    #arr_msk  = np.select((arr_sta>0,), (arr0,), 1)

    logger.debug(info_ndarr(arr_av1, 'proc time = %.3f sec arr_av1' % (time()-t0_sec)))
    logger.debug(info_ndarr(arr_rms, 'pixel_rms'))
    logger.debug(info_ndarr(arr_sta, 'pixel_status'))

    #return block.mean(0)
    return arr_av1, arr_rms, arr_sta


def selected_record(nrec):
    return nrec<5\
       or (nrec<50 and not nrec%10)\
       or (nrec<500 and not nrec%100)\
       or (not nrec%1000)


def print_statistics(nevt, nrec):
    logger.debug('statistics nevt:%d nrec:%d lost frames:%d' % (nevt, nrec, nevt-nrec))


def irun_first(runs):
    """Returns the 1st (int) run number from list or string or int
    """
    return runs[0] if isinstance(runs, list) else\
           runs if isinstance(runs, int) else\
           int(runs.split(',',1)[0].split('-',1)[0])


def data_source_kwargs(**opts):
    """Makes from input **opts and returns dict of arguments **kwa for DataSource(**kwa)
    """
    fname      = opts.get('fname', None)
    detname    = opts.get('det', None)
    exp        = opts.get('exp', None)
    runs       = opts.get('runs', None)
    dirxtc     = opts.get('dirxtc', None)
    usesmd     = opts.get('usesmd', False)

    irun = irun_first(runs)

    kwa = {'files':fname} if fname else {'exp':exp,'run':irun}
    if dirxtc: kwa['dir'] = dirxtc
    logger.debug('DataSource **kwargs: %s' % str(kwa))
    #exit('TEST EXIT')
    return kwa


def pedestals_calibration(*args, **opts):
    """NEWS significant ACCELERATION is acheived:
       - accumulate data for entire epix10kam_2m/quad array
       - use MPI 
       all-panel or selected-panel one-step (gain range) or all steps calibration of pedestals
    """
    fname      = opts.get('fname', None)
    detname    = opts.get('det', None)
    exp        = opts.get('exp', None)
    runs       = opts.get('runs', None)
    nbs        = opts.get('nbs', 1024)
    stepnum    = opts.get('stepnum', None)
    stepmax    = opts.get('stepmax', 5)
    dirxtc     = opts.get('dirxtc', None)
    dirrepo    = opts.get('dirrepo', CALIB_REPO_EPIX10KA)
    fmt_peds   = opts.get('fmt_peds', '%.3f')
    fmt_rms    = opts.get('fmt_rms',  '%.3f')
    fmt_status = opts.get('fmt_status', '%4i')
    idx_sel    = opts.get('idx', None)
    dirmode    = opts.get('dirmode', 0o777)
    filemode   = opts.get('filemode', 0o666)
    usesmd     = opts.get('usesmd', False)
    logmode    = opts.get('logmode', 'DEBUG')
    errskip    = opts.get('errskip', False)

    logger.setLevel(DICT_NAME_TO_LEVEL[logmode])

    #irun = runs[0] if isinstance(runs, list) else\
    #       int(runs.split(',',1)[0].split('-',1)[0]) # int first run number from str of run(s)
    irun = irun_first(runs)

    #dsname = 'exp=%s:run=%s'%(exp,runs) if dirxtc is None else 'exp=%s:run=%s:dir=%s'%(exp, runs, dirxtc)
    #if usesmd: dsname += ':smd'

    _name = sys._getframe().f_code.co_name
    logger.info('In %s\n  exp: %s\n  runs: %s\n  detector: %s' % (_name, exp, str(runs), detname))
    save_log_record_on_start(dirrepo, _name, dirmode)

    #cpdic = get_config_info_for_dataset_detname(dsname, detname)
    #tstamp      = cpdic.get('tstamp', None)
    #panel_ids   = cpdic.get('panel_ids', None)
    #expnum      = cpdic.get('expnum', None)
    #dettype     = cpdic.get('dettype', None)
    #shape       = cpdic.get('shape', None)
    #ny,nx = shape

    #panel_id = get_panel_id(panel_ids, idx)
    #logger.debug('Found panel ids:\n%s' % ('\n'.join(panel_ids)))

    #read input xtc file and accumulate block of data

    #================= MPI

    #from mpi4py import MPI
    #comm = MPI.COMM_WORLD
    #rank = comm.Get_rank()
    #size = comm.Get_size() # number of MPI nodes; 1 for regular python command

    #=================

    kwa = data_source_kwargs(**opts)
    ds = DataSource(**kwa)
    logger.debug('ds.runnum_list = %s' % str(ds.runnum_list))
    logger.debug('ds.detectors = %s' % str(ds.detectors))
    
    mode = None # gain_mode
    nstep_tot = -1

    #orun = next(ds.runs())
    for orun in ds.runs():
      logger.debug('==run.runnum   : %d' % orun.runnum)        # 27
      logger.debug('  run.detnames : %s' % str(orun.detnames)) # {'epixquad'}
      logger.debug('  run.expt     : %s', orun.expt)           # ueddaq02

      runtstamp = orun.timestamp    # 4193682596073796843 relative to 1990-01-01
      trun_sec = ue.seconds(runtstamp) # 1607569818.532117 sec
      #tstamp = str_tstamp(time_sec=int(trun_sec)) #fmt='%Y-%m-%dT%H:%M:%S%z'

      tstamp_run, tstamp_now = tstamps_run_and_now(int(trun_sec))
      tstamp = tstamp_run

      logger.debug('  run.timestamp: %d' % orun.timestamp) 
      logger.debug('  run unix epoch time %06f sec' % trun_sec)
      logger.debug('  run tstamp: %s' % tstamp_run)
      logger.debug('  now tstamp: %s' % tstamp_now)
      det = orun.Detector(detname)
      step_value = orun.Detector('step_value')
      step_docstring = orun.Detector('step_docstring')
      #cd = orun.Detector('ControlData') #LCLS1

      logger.debug('--- det.raw._det_name: %s' % det.raw._det_name) # epixquad
      logger.debug('    det.raw._dettype : %s' % det.raw._dettype)  # epix
      logger.debug('    det.raw._calibconst.keys(): %s' % str(det.raw._calibconst.keys())) # dict_keys(['geometry'])
      #logger.debug('    det.raw._uniqueid: %s' % det.raw._uniqueid)
      #logger.debug('    det.raw._sorted_segment_ids: %s' % str(det.raw._sorted_segment_ids))
      #logger.debug('    ue.fullname_epix10ka_detector: %s' % ue.fullname_epix10ka_detector(det))

      segment_ids = ue.segment_ids_epix10ka_detector(det)
      segment_inds = ue.segment_indices_epix10ka_detector(det)
      s = 'segment inds and ids in the detector'
      for i,id in zip(segment_inds,segment_ids):
          s += '\n  seg:%02d id:%s' % (i,id)
      logger.info(s)

      #logger.debug('    ue.segment_ids_epix10ka_detector: %s' % str(ue.segment_ids_epix10ka_detector(det)))
      #logger.debug('    ue.segment_indices_epix10ka_detector: %s' % str(ue.segment_indices_epix10ka_detector(det)))

      dcfg = ue.config_object_epix10ka(det)

      for nstep_run, step in enumerate(orun.steps()): #(loop through calyb cycles, using only the first):
        nstep_tot += 1
        logger.info('\n=============== step %2d ===============' % nstep_tot)
        logger.debug('    step.evt._seconds: %d' % step.evt._seconds)

        metadic = json.loads(step_docstring(step))
        nstep = step_counter(metadic, nstep_tot, nstep_run, stype='pedestal')

        if nstep is None: continue

        #if size > 1:
        #    # if MPI is on process all steps, step per rank
        #    if nstep < rank: continue
        #    if nstep > rank: break

        if nstep_tot>=stepmax: break

        elif stepnum is not None:
            # process step stepnum ONLY if stepnum is specified and MPI is not used!!!
            if   nstep < stepnum: continue
            elif nstep > stepnum: break

        #for k,v in det.raw._seg_configs().items(): # cpo's pattern DOES NOT WORK
        for k,v in dcfg.items():
            scob = v.config
            logger.info(info_ndarr(scob.asicPixelConfig[:,:-2,:], 'seg:%02d trbits: %s asicPixelConfig:'%(k, str(scob.trbit))))

        gmaps = ue.gain_maps_epix10ka_any(dcfg, data=None)
        logger.debug('gain mode statistics:' + ue.info_pixel_gain_mode_statistics(gmaps))
        logger.debug(ue.info_pixel_gain_mode_fractions(dcfg, data=None, msg='gain mode fractions :'))

        logger.debug('gain maps'\
          + info_ndarr(gmaps[0],'\n    FH  ')\
          + info_ndarr(gmaps[1],'\n    FM  ')\
          + info_ndarr(gmaps[2],'\n    FL  ')\
          + info_ndarr(gmaps[3],'\n    AHL ')\
          + info_ndarr(gmaps[4],'\n    AML ')\
        )

        mode = ue.find_gain_mode(dcfg, data=None).upper()

        if mode in ue.GAIN_MODES_IN:
            mode_in_step = ue.GAIN_MODES_IN[nstep]
            logger.info('== step %d: dark run processing for gain mode in configuration %s and step number %s'\
                        %(nstep, mode, mode_in_step))
            if mode != mode_in_step:
              logger.warning('INCONSISTENT GAIN MODES IN CONFIGURATION AND STEP NUMBER/METADATA')
              if not errskip: sys.exit()
              logger.warning('FLAG ERRSKIP IS %s - keep processing next step' % errskip)
              #continue
        else:
            logger.warning('UNRECOGNIZED GAIN MODE: %s, DARKS NOT UPDATED...'%mode)
            sys.exit()
            #return

        sh = gmaps[0].shape
        shape_block = [nbs,] + list(sh) # [nbs, <number-of-segments>, 352, 384]
        logger.info('Accumulate raw frames in block shape = %s' % str(shape_block))

        block=np.zeros(shape_block,dtype=np.int16)
        nrec,nevt = -1,0

        for nevt,evt in enumerate(step.events()):
            raw = det.raw.raw(evt)
            do_print = selected_record(nevt)
            if raw is None:
                logger.warning('==== Ev:%04d rec:%04d raw=None' % (nevt,nrec))
                continue
            if nrec>nbs-2:       # stop after collecting sufficient frames
                break
            else:
                #if raw.ndim > 2: raw=raw[idx,:]
                nrec += 1
                if do_print: logger.info(info_ndarr(raw & ue.M14, 'Ev:%04d rec:%04d raw & M14 ' % (nevt,nrec)))
                block[nrec]=raw & ue.M14

        print_statistics(nevt, nrec)

        #---- process statistics in block-array for panels

        for idx, panel_id in zip(segment_inds,segment_ids):

            if idx_sel is not None and idx_sel != idx: continue # skip panels with inices other than idx_sel if specified

            logger.info('\n%s\nprocess panel:%02d id:%s' % (96*'=', idx, panel_id))

            #if mode is None:
            #    msg = 'Gain mode for dark processing is not defined "%s" try to set option -m <gain-mode>' % mode
            #    logger.warning(msg)
            #    sys.exit(msg)

            dir_panel, dir_offset, dir_peds, dir_plots, dir_work, dir_gain, dir_rms, dir_status = dir_names(dirrepo, panel_id)

            #print('XXXX panel_id, tstamp, exp, irun', panel_id, tstamp, exp, irun)

            fname_prefix, panel_alias = file_name_prefix(dirrepo, panel_id, tstamp, exp, irun)
            logger.debug('\n  fname_prefix:%s\n  panel_alias :%s' % (fname_prefix, panel_alias))

            prefix_offset, prefix_peds, prefix_plots, prefix_gain, prefix_rms, prefix_status =\
                path_prefixes(fname_prefix, dir_offset, dir_peds, dir_plots, dir_gain, dir_rms, dir_status)

            #logger.debug('Directories under %s\n  SHOULD ALREADY EXIST after charge-injection offset_calibration' % dir_panel)
            #assert os.path.exists(dir_offset), 'Directory "%s" DOES NOT EXIST' % dir_offset
            #assert os.path.exists(dir_peds),   'Directory "%s" DOES NOT EXIST' % dir_peds        
 
            create_directory(dir_panel,  mode=dirmode)
            create_directory(dir_peds,   mode=dirmode)
            create_directory(dir_offset, mode=dirmode)
            create_directory(dir_gain,   mode=dirmode)
            create_directory(dir_rms,    mode=dirmode)
            create_directory(dir_status, mode=dirmode)


            #dark=block[:nrec,:].mean(0)  #Calculate mean

            #block.sahpe = (1024, 16, 352, 384)
            dark, rms, status = proc_dark_block(block[:nrec,idx,:], **opts) # process pedestals per-panel (352, 384)


            #continue # TEST
            #==========

            fname = '%s_pedestals_%s.dat' % (prefix_peds, mode)
            save_2darray_in_textfile(dark, fname, filemode, fmt_peds)

            fname = '%s_rms_%s.dat' % (prefix_rms, mode)
            save_2darray_in_textfile(rms, fname, filemode, fmt_rms)

            fname = '%s_status_%s.dat' % (prefix_status, mode)
            save_2darray_in_textfile(status, fname, filemode, fmt_status)

            #if this is an auto gain ranging mode, also calculate the corresponding _L pedestal:

            if mode=='AHL-H': # evaluate AHL_L from AHL_H
                ped_hl_h = dark #[3,:,:]

                offset_hl_h = load_panel_constants(dir_offset, 'offset_AHL-H', tstamp)
                offset_hl_l = load_panel_constants(dir_offset, 'offset_AHL-L', tstamp)
                gain_hl_h   = load_panel_constants(dir_gain,   'gainci_AHL-H', tstamp)
                gain_hl_l   = load_panel_constants(dir_gain,   'gainci_AHL-L', tstamp)

                #if offset is not None:
                if not None in (offset_hl_h, offset_hl_l, gain_hl_h, gain_hl_l):
                    ped_hl_l = offset_hl_l - (offset_hl_h - ped_hl_h) * divide_protected(gain_hl_l, gain_hl_h) #V3 Gabriel's
                    fname = '%s_pedestals_AHL-L.dat' % prefix_peds
                    save_2darray_in_textfile(ped_hl_l, fname, filemode, fmt_peds)

            elif mode=='AML-M': # evaluate AML_L from AML_M
                ped_ml_m = dark #[4,:,:]

                offset_ml_m = load_panel_constants(dir_offset, 'offset_AML-M', tstamp)
                offset_ml_l = load_panel_constants(dir_offset, 'offset_AML-L', tstamp)
                gain_ml_m   = load_panel_constants(dir_gain,   'gainci_AML-M', tstamp)
                gain_ml_l   = load_panel_constants(dir_gain,   'gainci_AML-L', tstamp)

                #if offset is not None:
                if not None in (offset_ml_m, offset_ml_l, gain_ml_m, gain_ml_l):
                    ped_ml_l = offset_ml_l - (offset_ml_m - ped_ml_m) * divide_protected(gain_ml_l, gain_ml_m) #V3 Gabriel's
                    fname = '%s_pedestals_AML-L.dat' % prefix_peds
                    save_2darray_in_textfile(ped_ml_l, fname, filemode, fmt_peds)
    #logger.info('==== Completed pedestal calibration for rank %d ==== ' % rank)


def get_config_info_for_dataset_detname(**kwargs):

    detname = kwargs.get('det', None)
    idx     = kwargs.get('idx', None)

    ds = DataSource(**data_source_kwargs(**kwargs))
    logger.debug('ds.runnum_list = %s' % str(ds.runnum_list))
    logger.debug('ds.detectors = %s' % str(ds.detectors))

    #for orun in ds.runs():
    orun = next(ds.runs())
    if orun:

      logger.debug('==run.runnum   : %d' % orun.runnum)        # 27
      logger.debug('  run.detnames : %s' % str(orun.detnames)) # {'epixquad'}
      logger.debug('  run.expt     : %s', orun.expt)           # ueddaq02

      runtstamp = orun.timestamp       # 4193682596073796843 relative to 1990-01-01
      trun_sec = ue.seconds(runtstamp) # 1607569818.532117 sec
      #tstamp_run = str_tstamp(time_sec=int(trun_sec)) #fmt='%Y-%m-%dT%H:%M:%S%z'
      tstamp_run, tstamp_now = tstamps_run_and_now(int(trun_sec)) # (str) 20201209191018, 20201217140026
      logger.debug('  run.timestamp: %d' % orun.timestamp) 
      logger.debug('  run unix epoch time %06f sec' % trun_sec)
      logger.debug('  run tstamp: %s' % tstamp_run)
      logger.debug('  now tstamp: %s' % tstamp_now)

      det = orun.Detector(detname)

      co = ue.config_object_epix10ka(det)

      cpdic = {}
      cpdic['expname']    = orun.expt
      cpdic['calibdir']   = None
      cpdic['strsrc']     = None
      cpdic['shape']      = (352, 384)
      cpdic['gain_mode']  = ue.find_gain_mode(co, data=None) #data=raw: distinguish 5-modes w/o data
      cpdic['panel_ids']  = ue.segment_ids_epix10ka_detector(det)
      cpdic['panel_inds'] = ue.segment_indices_epix10ka_detector(det)
      cpdic['longname']   = ue.fullname_epix10ka_detector(det) #det.raw._uniqueid
      cpdic['dettype']    = det._dettype # epix
      cpdic['tstamp']     = tstamp_run # (str) 20201209191018
      cpdic['tstamp_now'] = tstamp_now # (str) 20201217140026
      cpdic['trun_sec']   = int(trun_sec) # 1607569818.532117 sec
      cpdic['tsrun_db']   = str_tstamp(time_sec=int(trun_sec)) #fmt='%Y-%m-%dT%H:%M:%S%z'

      return cpdic


def merge_panel_gain_ranges(dir_ctype, panel_id, ctype, tstamp, shape, ofname, fmt='%.3f', fac_mode=0o777):

    logger.debug('In merge_panel_gain_ranges for\n  dir_ctype: %s\n  id: %s\n  ctype=%s tstamp=%s shape=%s'%\
                 (dir_ctype, panel_id, ctype, str(tstamp), str(shape)))

    nda_def = np.ones(shape, dtype=np.float32) if ctype in ('gain', 'gainci', 'rms') else\
              np.zeros(shape, dtype=np.float32)

    lstnda = []
    for igm,gm in enumerate(ue.GAIN_MODES):
        fname = None if gm in ue.GAIN_MODES[5:] and ctype in ('status', 'rms') else\
                find_file_for_timestamp(dir_ctype, '%s_%s' % (ctype,gm), tstamp)
        nda = np.loadtxt(fname, dtype=np.float32) if fname is not None else\
              nda_def*GAIN_FACTOR_DEF[igm] if ctype in ('gain', 'gainci') else\
              nda_def 

        # normalize gains for ctype 'gainci'
        if fname is not None and ctype == 'gainci':
            med_nda = np.median(nda)
            dir_gain = dir_ctype
            if med_nda != 0:
                f_adu_to_kev = 0

                if gm in GAIN_MODES_IN: # 'FH','FM','FL','AHL-H','AML-M' # 'AHL-L','AML-L'
                    f_adu_to_kev = GAIN_FACTOR_DEF[igm] / med_nda
                    nda = nda * f_adu_to_kev

                elif gm=='AHL-L': 
                    #gain_hl_l = load_panel_constants(dir_gain, 'gainci_AHL-L', tstamp)
                    gain_hl_h = load_panel_constants(dir_gain, 'gainci_AHL-H', tstamp)
                    if gain_hl_h is None: continue
                    med_hl_h = np.median(gain_hl_h)
                    #V1
                    #ratio_lh = med_nda/med_hl_h if med_hl_h>0 else 0
                    #f_adu_to_kev = ratio_lh * GAIN_FACTOR_DEF[3] / med_nda
                    f_adu_to_kev = GAIN_FACTOR_DEF[3] / med_hl_h if med_hl_h>0 else 0
                    nda *= f_adu_to_kev
                    #V2
                    #nda = GAIN_FACTOR_DEF[3] * divide_protected(nda, gain_hl_h)

                elif gm=='AML-L': 
                    #gain_ml_l = load_panel_constants(dir_gain, 'gainci_AML-L', tstamp)
                    gain_ml_m = load_panel_constants(dir_gain, 'gainci_AML-M', tstamp)
                    if gain_ml_m is None: continue
                    med_ml_m = np.median(gain_ml_m)
                    #V1
                    #ratio_lm = med_nda/med_ml_m if med_ml_m>0 else 0
                    #f_adu_to_kev = ratio_lm * GAIN_FACTOR_DEF[4] / med_nda
                    f_adu_to_kev = GAIN_FACTOR_DEF[4] / med_ml_m if med_ml_m>0 else 0
                    nda *= f_adu_to_kev
                    #V2
                    #nda = GAIN_FACTOR_DEF[4] * divide_protected(nda, gain_ml_m)

                    #logger.info('XXXX gm',gm)
                    #logger.info('XXXX med_nda',med_nda)
                    #logger.info('XXXX med_ml_m',med_ml_m)
                    #logger.info('XXXX GAIN_FACTOR_DEF[4]',GAIN_FACTOR_DEF[4])
                    #logger.info('XXXX ratio_lh',ratio_lh)
                    #logger.info('XXXX f_adu_to_kev',f_adu_to_kev)

        lstnda.append(nda if nda is not None else nda_def)
        #logger.debug(info_ndarr(nda, 'nda for %s' % gm))
        #logger.info('%5s : %s' % (gm,fname))

 
    logger.debug('merge per-gain-range data in segment nda:\n'+'\n'.join([info_ndarr(a,'    ') for a in lstnda]))

    nda = np.stack(tuple(lstnda))
    logger.debug('merge_panel_gain_ranges - merged with shape %s' % str(nda.shape))

    nda.shape = (7, 1, 352, 384)
    logger.debug(info_ndarr(nda, 'merged %s'%ctype))
    save_ndarray_in_textfile(nda, ofname, fac_mode, fmt)

    nda.shape = (7, 1, 352, 384) # because save_ndarray_in_textfile changes shape
    return nda


def merge_panels(lst):
    """ stack of 16 (or 4 or 1) arrays from list shaped as (7, 1, 352, 384) to (7, 16, 352, 384)
    """
    npanels = len(lst)   # 16 or 4 or 1
    shape = lst[0].shape # (7, 1, 352, 384)
    ngmods = shape[0]    # 7

    logger.debug('In merge_panels: number of panels %d number of gain modes %d' % (npanels,ngmods))

    # make list for merging of (352,384) blocks in right order
    mrg_lst = []
    for igm in range(ngmods):
        nda1gm = np.stack([lst[ind][igm,0,:] for ind in range(npanels)])
        mrg_lst.append(nda1gm)
    return np.stack(mrg_lst)


def add_links_for_gainci_fixed_modes(dir_gain, fname_prefix):
    """FH->AHL-H, FM->AML-M, FL->AML-L/AHL-L"""
    logger.debug('in add_links_for_gainci_fixed_modes, prefix: %s' % (fname_prefix))
    list_of_files = '\n    '.join([name for name in os.listdir(dir_gain)])
    logger.debug('list_of_files in %s:\n    %s' %(dir_gain, list_of_files))

    dic_links = {'FH': 'AHL-H',
                 'FM': 'AML-M',
                 'FL': 'AML-L'} # 'AHL-L'
    for k,v in dic_links.items():
        fname_auto  = '%s/%s_gainci_%s.dat' % (dir_gain, fname_prefix, v)
        fname_fixed = '%s/%s_gainci_%s.dat' % (dir_gain, fname_prefix, k)
        #logger.info('file %s existx %s' % (fname_auto, os.path.exists(fname_auto)))
        if os.path.exists(fname_auto) and not os.path.lexists(fname_fixed): 
            os.symlink(os.path.abspath(fname_auto), fname_fixed)
    return


def deploy_constants(*args, **opts):

    #from PSCalib.NDArrIO import save_txt; global save_txt
    from psana.pscalib.calib.NDArrIO import save_txt; global save_txt

    exp        = opts.get('exp', None)     
    detname    = opts.get('det', None)   
    runs       = opts.get('runs', None)    
    tstamp     = opts.get('tstamp', None)    
    dirxtc     = opts.get('dirxtc', None) 
    dirrepo    = opts.get('dirrepo', CALIB_REPO_EPIX10KA)
    dircalib   = opts.get('dircalib', None)
    deploy     = opts.get('deploy', False)
    fmt_peds   = opts.get('fmt_peds', '%.3f')
    fmt_gain   = opts.get('fmt_gain', '%.6f')
    fmt_rms    = opts.get('fmt_rms',  '%.3f')
    fmt_status = opts.get('fmt_status', '%4i')
    logmode    = opts.get('logmode', 'DEBUG')
    dirmode    = opts.get('dirmode',  0o777)
    filemode   = opts.get('filemode', 0o666)
    high       = opts.get('high',   16.40) # ADU/keV #High gain: 132 ADU / 8.05 keV = 16.40 ADU/keV
    medium     = opts.get('medium', 5.466) # ADU/keV #Medium gain: 132 ADU / 8.05 keV / 3 = 5.466 ADU/keV
    low        = opts.get('low',    0.164) # ADU/keV#Low gain: 132 ADU / 8.05 keV / 100 = 0.164 ADU/keV
    proc       = opts.get('proc', 'prsg')
    paninds    = opts.get('paninds', None)

    logger.setLevel(DICT_NAME_TO_LEVEL[logmode])

    #dsname = 'exp=%s:run=%d'%(exp,irun) if dirxtc is None else 'exp=%s:run=%d:dir=%s'%(exp, irun, dirxtc)
    irun = irun_first(runs)
    _name = sys._getframe().f_code.co_name

    save_log_record_on_start(dirrepo, _name, dirmode)

    cpdic = get_config_info_for_dataset_detname(**opts)
    tstamp_run  = cpdic.get('tstamp',    None)
    expnum      = cpdic.get('expnum',    None)
    shape       = cpdic.get('shape',     None)
    calibdir    = cpdic.get('calibdir',  None)
    strsrc      = cpdic.get('strsrc',    None)
    panel_ids   = cpdic.get('panel_ids', None)
    panel_inds  = cpdic.get('panel_inds',None)
    dettype     = cpdic.get('dettype',   None)

    req_inds = None if paninds is None else [int(i) for i in paninds.split(',')] # conv str '0,1,2,3' to list [0,1,2,3] 
    logger.info('In %s\n      detector: "%s" \n      requested_inds: %s' % (_name, detname, str(req_inds)))

    global GAIN_FACTOR_DEF
    #GAIN_MODES     = ['FH','FM','FL','AHL-H','AML-M','AHL-L','AML-L']
    GAIN_FACTOR_DEF = [high, medium, low, high, medium, low, low]

    CTYPE_FMT = {'pedestals'   : fmt_peds,
                 'pixel_gain'  : fmt_gain,
                 'pixel_rms'   : fmt_rms,
                 'pixel_status': fmt_status}

    logger.debug('detector "%s" panel ids:\n  %s' % (detname, '\n  '.join(panel_ids)))

    #tstamp = tstamp_run if tstamp is None else tstamp
             #tstamp if int(tstamp)>9999 else\
             #tstamp_for_dataset('exp=%s:run=%d'%(exp,tstamp))

    if tstamp is None: tstamp = tstamp_run

    logger.debug('search for calibration files with tstamp <= %s' % tstamp)

    # dict_consts for constants octype: 'pixel_gain', 'pedestals', etc.
    dic_consts = {} 
    for ind, panel_id in zip(panel_inds,panel_ids):

        if req_inds is not None and not (ind in req_inds): continue # skip non-selected panels

        logger.info('%s\nmerge constants for panel:%02d id: %s' % (98*'_', ind, panel_id))

        dir_panel, dir_offset, dir_peds, dir_plots, dir_work, dir_gain, dir_rms, dir_status = dir_names(dirrepo, panel_id)
        fname_prefix, panel_alias = file_name_prefix(dirrepo, panel_id, tstamp, exp, irun)

        prefix_offset, prefix_peds, prefix_plots, prefix_gain, prefix_rms, prefix_status =\
            path_prefixes(fname_prefix, dir_offset, dir_peds, dir_plots, dir_gain, dir_rms, dir_status)

        #mpars = (('pedestals', 'pedestals',    prefix_peds,   dir_peds),\
        #         ('rms',       'pixel_rms',    prefix_rms,    dir_rms),\
        #         ('status',    'pixel_status', prefix_status, dir_status),\
        #         ('gain',      'pixel_gain',   prefix_gain,   dir_gain))

        mpars = []
        if 'p' in proc: mpars.append(('pedestals', 'pedestals',    prefix_peds,   dir_peds))
        if 'r' in proc: mpars.append(('rms',       'pixel_rms',    prefix_rms,    dir_rms))
        if 's' in proc: mpars.append(('status',    'pixel_status', prefix_status, dir_status))
        if 'g' in proc: mpars.append(('gain',      'pixel_gain',   prefix_gain,   dir_gain))
        if 'c' in proc: mpars.append(('gainci',    'pixel_gain',   prefix_gain,   dir_gain))
        if 'c' in proc:
             add_links_for_gainci_fixed_modes(dir_gain, fname_prefix) # FH->AHL-H, FM->AML-M, FL->AML-L/AHL-L

        for (ctype, octype, prefix, dir_ctype) in mpars:
            fmt = CTYPE_FMT.get(octype,'%.5f')
            logger.debug('begin merging for ctype:%s, octype:%s, fmt:%s,\n  prefix:%s' % (ctype, octype, fmt, prefix))
            fname = '%s_%s.txt' % (prefix, ctype)
            nda = merge_panel_gain_ranges(dir_ctype, panel_id, ctype, tstamp, shape, fname, fmt, filemode)
            if octype in dic_consts: dic_consts[octype].append(nda) # append for panel per ctype
            else:                    dic_consts[octype] = [nda,]


    logger.info('\n%s\nMERGE PANEL CONSTANTS AND DEPLOY THEM\n' % (80*'_'))

    if deploy:
       import psana.pscalib.calib.MDBUtils as mu
       import psana.pscalib.calib.MDBWebUtils as wu
       cc = wu.cc

    dmerge = dir_merge(dirrepo)
    create_directory(dmerge, mode=dirmode)
    fmerge_prefix = fname_prefix_merge(dmerge, detname, tstamp, exp, irun)

    for octype, lst in dic_consts.items():
        mrg_nda = merge_panels(lst)
        logger.info(info_ndarr(mrg_nda, 'merged constants for %s ' % octype))
        fmerge = '%s-%s.txt' % (fmerge_prefix, octype)
        fmt = CTYPE_FMT.get(octype,'%.5f')
        save_ndarray_in_textfile(mrg_nda, fmerge, filemode, fmt)


        if deploy:

          dtype = 'ndarray'

          kwa = {
            'iofname': fmerge,
            'experiment': exp,
            'ctype': octype,
            'dtype': dtype,
            'detector': detname,
            'longname': cpdic.get('longname', None),
            'time_sec': cpdic.get('trun_sec', None),
            'time_stamp': cpdic.get('tsrun_db', None),
            'run': irun,
            'run_end': opts.get('run_end', None),
            'version': opts.get('version', None),
            'comment': opts.get('comment', None),
          }

          logger.debug('DEPLOY metadata:', str(kwa))

          _detname = detname # cpdic.get('longname', None)

          data = mu.data_from_file(fmerge, octype, dtype, True)
          id_data_exp, id_data_det, id_doc_exp, id_doc_det =\
            wu.add_data_and_two_docs(data, exp, _detname, **kwa) # url=cc.URL_KRB, krbheaders=cc.KRBHEADERS

#----

if __name__ == "__main__":

  def test_pedestals_calibration_epix10ka(tname):
    #print('DATA FILE IS AVAILABLE ON drp-ued-cmp001 ONLY')
    #  fname = '/u2/pcds/pds/ued/ueddaq02/xtc/ueddaq02-r0027-s000-c000.xtc2',\
    #  fname = '/reg/d/psdm/ued/ueddaq02/xtc/ueddaq02-r0027-s000-c000.xtc2',\
    pedestals_calibration(
      fname = '/cds/data/psdm/ued/ueddaq02/xtc/ueddaq02-r0027-s000-c000.xtc2',\
      det     = 'epixquad',\
      exp     = 'ueddaq02',\
      runs    = [27,],\
      nbs     = 1024,\
      errskip = True,\
      idx     = None,\
      )
      #stepnum = 1,\
      #mode    = 'AML-M',\
      #dirrepo = './work',
      #dirxtc  = DIR_XTC_TEST,\
      #stepnum = 2,\


  def test_offset_calibration_epix10ka(tname):
    print('TBD')


  def test_deploy_constants_epix10ka(tname):
    deploy_constants(
      exp     = 'ueddaq02',\
      det     = 'epixquad',\
      runs    = 27,\
      tstamp  = 20201216000000,\
      dirxtc  = '/cds/data/psdm/ued/ueddaq02/xtc/',\
      dircalib= './calib',\
      deploy  = False)
      #dirrepo = './work',\
    print('TBD')


  SCRNAME = sys.argv[0].rsplit('/')[-1]
  USAGE = 'python %s <test-name>' % SCRNAME\
        + '\n  where <test-name>'\
        + '\n  1: test_offset_calibration_epix10ka - TBD'\
        + '\n  2: test_pedestals_calibration_epix10ka'\
        + '\n  3: test_deploy_constants_epix10ka - TBD'\
        + '\n'
 
if __name__ == "__main__":
    print(80*'_')
    logging.basicConfig(format='[%(levelname).1s] L%(lineno)04d: %(message)s', level=logging.DEBUG)
    tname = sys.argv[1] if len(sys.argv)>1 else '0'
    if   tname == '1': test_offset_calibration_epix10ka(tname)
    elif tname == '2': test_pedestals_calibration_epix10ka(tname)
    elif tname == '3': test_deploy_constants_epix10ka(tname)
    else:
        print('Usage: %s'%USAGE)
        sys.exit('Not recognized test name: "%s"' % tname)
    sys.exit('End of %s' % sys.argv[0])

#----
