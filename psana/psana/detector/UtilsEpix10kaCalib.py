"""
Created on Fri May 11 18:25:48 2018
CALIBRATION - TEST PULSES
@author: Gabriel Blaj

2020-12-03 - Mikhail Dubrovin - begin conversion to LCLS2
"""
import os
import sys
from time import time
import logging
logger = logging.getLogger(__name__)
DICT_NAME_TO_LEVEL = logging._nameToLevel
#print('DICT_NAME_TO_LEVEL:',DICT_NAME_TO_LEVEL)
#{'CRITICAL': 50, 'FATAL': 50, 'ERROR': 40, 'WARN': 30, 'WARNING': 30, 'INFO': 20, 'DEBUG': 10, 'NOTSET': 0}
SCRNAME = sys.argv[0].rsplit('/')[-1]

import numpy as np

import json
from psana import DataSource
from psana.detector.UtilsEpix import CALIB_REPO_EPIX10KA, FNAME_PANEL_ID_ALIASES, alias_for_id
from psana.detector.Utils import log_rec_at_start, str_tstamp, create_directory, save_textfile, set_file_access_mode, time_sec_from_stamp, get_login
from psana.detector.NDArrUtils import info_ndarr, divide_protected, save_2darray_in_textfile, save_ndarray_in_textfile
import psana.detector.UtilsEpix10ka as ue
from psana.detector.utils_psana import seconds
from psana.detector.UtilsLogging import init_file_handler


def save_log_record_at_start(dirrepo, procname, dirmode=0o777, filemode=0o666, logmode='INFO', tsfmt='%Y-%m-%dT%H:%M:%S%z', umask=0o0):
    """Adds record on start to the log file <dirrepo>/logs/log-<procname>-<year>.txt
    """
    from psana.detector.RepoManager import RepoManager
    os.umask(umask)
    repoman = RepoManager(dirrepo, dettype=None, dirmode=dirmode, filemode=filemode)
    repoman.makedir_logs()
    logfname = repoman.logname('%s_%s' % (procname, get_login()))
    init_file_handler(logmode, logfname, filemode=0o664)
    logger.info('Begin logfile: %s' % logfname)
    repoman.save_record_at_start(SCRNAME, tsfmt=tsfmt)

#    create_directory(dirrepo, dirmode)
#    dirlog = '%s/logs' % dirrepo
#    create_directory(dirlog, dirmode)

#    rec = log_rec_at_start(tsfmt)
#    year = str_tstamp(fmt='%Y')
#    logfname = '%s/log_%s_%s.txt' % (dirlog, procname, year)
#    fexists = os.path.exists(logfname)
#    save_textfile(rec, logfname, mode='a')
#    if not fexists: set_file_access_mode(logfname, dirmode)
#    logger.debug('Record on start: %s' % rec)
#    logger.info('Saved: %s' % logfname)


def find_file_for_timestamp(dirname, pattern, tstamp):
    # list of file names in directory, dirname, containing pattern
    fnames = [name for name in os.listdir(dirname) if os.path.splitext(name)[-1]=='.dat' and pattern in name]

    # list of int tstamps
    # !!! here we assume specific name structure generated by file_name_prefix
    itstamps = [int(name.split('_',3)[2]) for name in fnames]

    # reverse-sort int timestamps in the list
    itstamps.sort(key=int,reverse=True)

    # find the nearest to requested timestamp
    for its in itstamps:
        if its <= int(tstamp):
            # find and return the full file name for selected timestamp
            ts = str(its)

            for name in fnames:
                if ts in name:
                     fname = '%s/%s' % (dirname, name)
                     logger.info('  selected %s for %s and %s' % (os.path.basename(fname),pattern,tstamp))
                     return fname

    logger.debug('directory %s\n         DOES NOT CONTAIN file for pattern %s and timestamp <= %s'%\
                 (dirname,pattern,tstamp))
    return None


def load_panel_constants(dir_ctype, pattern, tstamp):
    fname = find_file_for_timestamp(dir_ctype, pattern, tstamp)
    arr=None
    if fname is not None and os.path.exists(fname):
        arr=np.loadtxt(fname)
        logger.info('Loaded: %s' % fname)
    else:
        logger.debug('file DOES NOT EXIST: %s' % fname)
        logger.debug('DO NOT save save constants for missing files')
    return arr


def dir_merge(dirrepo):
    return '%s/merge_tmp' % dirrepo


def fname_prefix_merge(dmerge, detname, tstamp, exp, irun):
    return '%s/%s-%s-%s-r%04d' % (dmerge, detname, tstamp, exp, irun)


def dir_names(dirrepo, panel_id):
    """Defines structure of subdirectories in calibration repository.
    """
    dir_panel  = '%s/%s' % (dirrepo, panel_id)
    dir_offset = '%s/offset'    % dir_panel
    dir_peds   = '%s/pedestals' % dir_panel
    dir_plots  = '%s/plots'     % dir_panel
    dir_work   = '%s/work'      % dir_panel
    dir_gain   = '%s/gain'      % dir_panel
    dir_rms    = '%s/rms'       % dir_panel
    dir_status = '%s/status'    % dir_panel
    return dir_panel, dir_offset, dir_peds, dir_plots, dir_work, dir_gain, dir_rms, dir_status


def path_prefixes(fname_prefix, dir_offset, dir_peds, dir_plots, dir_gain, dir_rms, dir_status):
    prefix_offset= '%s/%s' % (dir_offset, fname_prefix)
    prefix_peds  = '%s/%s' % (dir_peds,   fname_prefix)
    prefix_plots = '%s/%s' % (dir_plots,  fname_prefix)
    prefix_gain  = '%s/%s' % (dir_gain,   fname_prefix)
    prefix_rms   = '%s/%s' % (dir_rms,    fname_prefix)
    prefix_status= '%s/%s' % (dir_status, fname_prefix)
    return prefix_offset, prefix_peds, prefix_plots, prefix_gain, prefix_rms, prefix_status


def file_name_prefix(dirrepo, dettype, panel_id, tstamp, exp, irun):
    panel_alias = alias_for_id(panel_id, fname=os.path.join(dirrepo, FNAME_PANEL_ID_ALIASES))
    return '%s_%s_%s_%s_r%04d' % (dettype, panel_alias, tstamp, exp, irun), panel_alias


def tstamps_run_and_now(trun_sec): # unix epoch time, e.g. 1607569818.532117 sec
    """DEPRECATED HERE - USE FROM UtilsCalib.py
       Returns (str) tstamp_run, tstamp_now#, e.g. (str) 20201209191018, 20201217140026
    """
    ts_run = str_tstamp(fmt='%Y%m%d%H%M%S', time_sec=trun_sec)
    ts_now = str_tstamp(fmt='%Y%m%d%H%M%S', time_sec=None)
    return ts_run, ts_now


def step_counter(metadata, nstep_tot, nstep_run, stype='pedestal', nspace=None):
    #nspace=7 - for 103 charge injection calib-cycles, =None for 5 dark
    logger.info('step_counter metadata:%s nstep_tot:%d nstep_run:%d stype:%s nspace:%s'%\
                              (metadata, nstep_tot, nstep_run,stype, str(nspace)))
    if not metadata:
        logger.warning('STEP METADATA IS NOT AVAILABLE nstep_tot:%d, nstep_run:%d' % (nstep_tot, nstep_run))
        return nstep_tot

    assert isinstance(metadata, dict), 'UNEXPECTED non-dict DATA TYPE FOR METADATA: %s'%str(type(metadata))

    scantype = metadata['scantype']
    stepnum = metadata['step']

    if scantype != stype:
        logger.warning('UNEXPECTED SCAN TYPE %s' % scantype)
        return None

    # LCLS1
    #step_names = STEP_NAMES_DARK if nspace is None else step_names(nspace)
    #ind = step_names.index(step_value)
    #if ind in list_of_step_collected():
    #    logger.warning('CALIB-CYCLE %d: %s HAS ALREADY BEEN PROCESSED. SKIPPING' % (ind, step_value))
    #    return None

    if stepnum != nstep_tot:
        s = 'SEQUENTIAL STEP NUMBER nstep_tot:%d, nstep_run:%d' % (nstep_tot, nstep_run)
        s += ' IS NOT CONSISTENT WITH METADATA %s %d' % (scantype, stepnum)
        logger.warning(s)

    return stepnum


def mean_constrained(arr, lo, hi):
    """Evaluates mean value of the input array for values between low and high limits
    """
    condlist = (np.logical_not(np.logical_or(arr<lo, arr>hi)),)
    arr1 = np.ones(arr.shape, dtype=np.int32)
    arr_of1 = np.select(condlist, (arr1,), 0)
    arr_ofv = np.select(condlist, (arr,), 0)
    ngood = arr_of1.sum()
    return arr_ofv.sum()/ngood if ngood else None


def evaluate_limits(arr, nneg=5, npos=5, lim_lo=1, lim_hi=16000, cmt=''):
    """DEPRECATED HERE - USE FROM UtilsCalib.py
       Evaluates low and high limit of the array, which are used to find bad pixels.
    """
    ave, std = (arr.mean(), arr.std()) if (nneg>0 or npos>0) else (None,None)
    lo = ave-nneg*std if nneg>0 else lim_lo
    hi = ave+npos*std if npos>0 else lim_hi
    lo, hi = max(lo, lim_lo), min(hi, lim_hi)

    logger.debug('  %s: %s ave, std = %.3f, %.3f  low, high limits = %.3f, %.3f'%\
                 (sys._getframe().f_code.co_name, cmt, ave, std, lo, hi))

    return lo, hi


def proc_dark_block(block, **kwa):
    """DEPRECATED HERE - USE proc_block FROM UtilsCalib.py
       Returns per-panel (352, 384) arrays of mean, rms, ...
       block.shape = (nrecs, 352, 384), where nrecs <= 1024
    """
    exp        = kwa.get('exp', None)
    detname    = kwa.get('det', None)
    int_lo     = kwa.get('int_lo', 1)       # lowest  intensity accepted for dark evaluation
    int_hi     = kwa.get('int_hi', 16000)   # highest intensity accepted for dark evaluation
    intnlo     = kwa.get('intnlo', 6.0)     # intensity ditribution number-of-sigmas low
    intnhi     = kwa.get('intnhi', 6.0)     # intensity ditribution number-of-sigmas high
    rms_lo     = kwa.get('rms_lo', 0.001)   # rms ditribution low
    rms_hi     = kwa.get('rms_hi', 16000)   # rms ditribution high
    rmsnlo     = kwa.get('rmsnlo', 6.0)     # rms ditribution number-of-sigmas low
    rmsnhi     = kwa.get('rmsnhi', 6.0)     # rms ditribution number-of-sigmas high
    fraclm     = kwa.get('fraclm', 0.1)     # allowed fraction limit
    fraclo     = kwa.get('fraclo', 0.05)    # fraction of statistics below low gate limit
    frachi     = kwa.get('frachi', 0.95)    # fraction of statistics below high gate limit
    frac05     = 0.5
    nrecs1     = kwa.get('nrecs1', None)    # number of records for the 1st stage processing

    logger.debug('in proc_dark_block for exp=%s det=%s, block.shape=%s' % (exp, detname, str(block.shape)))
    logger.info(info_ndarr(block, 'Begin processing of the data block:\n    ', first=100, last=105))
    logger.debug('fraction of statistics for gate limits low: %.3f high: %.3f' % (fraclo, frachi))

    t0_sec = time()

    nrecs, ny, nx = block.shape
    shape = (ny, nx)
    if nrecs1 is None or nrecs1>nrecs: nrecs1 = nrecs

    arr1_u16 = np.ones(shape, dtype=np.uint16)
    arr1     = np.ones(shape, dtype=np.uint64)

    t1_sec = time()

    """
    NOTE:
    - our data is uint16.
    - np.median(block, axis=0) or np.quantile(...,interpolation='linear') return result rounded to int
    - in order to return interpolated float values apply the trick:
      data_block + random [0,1)-0.5
    - this would distort data in the range [-0.5,+0.5) ADU, but would allow to get better interpolation for median and quantile values
    - use nrecs1 (< nrecs) due to memory and time consumption
    """
    #blockf64 = np.random.random(block.shape) - 0.5 + block
    blockf64 = np.random.random((nrecs1, ny, nx)) - 0.5 + block[:nrecs1,:]
    logger.debug(info_ndarr(blockf64, '1-st stage conversion uint16 to float64, add random [0,1)-0.5 time = %.3f sec '%(time()-t1_sec), first=100, last=105))

    t1_sec = time()
    #arr_med = np.median(block, axis=0)
    arr_med = np.quantile(blockf64, frac05, axis=0, interpolation='linear')
    arr_qlo = np.quantile(blockf64, fraclo, axis=0, interpolation='linear')
    arr_qhi = np.quantile(blockf64, frachi, axis=0, interpolation='linear')
    logger.debug('block array median/quantile(0.5) for med, qlo, qhi time = %.3f sec' % (time()-t1_sec))

    med_med = np.median(arr_med)
    med_qlo = np.median(arr_qlo)
    med_qhi = np.median(arr_qhi)

    arr_dev_3d = block[:,] - arr_med # .astype(dtype=np.float64)
    arr_abs_dev = np.median(np.abs(arr_dev_3d), axis=0)
    med_abs_dev = np.median(arr_abs_dev)

    logger.info(info_ndarr(arr_med,     '    arr_med[100:105] ', first=100, last=105))
    logger.info(info_ndarr(arr_qlo,     '    arr_qlo[100:105] ', first=100, last=105))
    logger.info(info_ndarr(arr_qhi,     '    arr_qhi[100:105] ', first=100, last=105))
    logger.info(info_ndarr(arr_abs_dev, '    abs_dev[100:105] ', first=100, last=105))

    s = 'Pre-processing time %.3f sec' % (time()-t0_sec)\
      + '\nResults for median over pixels intensities:'\
      + '\n    %.3f fraction of the event spectrum is below %.3f ADU - pedestal estimator' % (frac05, med_med)\
      + '\n    %.3f fraction of the event spectrum is below %.3f ADU - gate low limit' % (fraclo, med_qlo)\
      + '\n    %.3f fraction of the event spectrum is below %.3f ADU - gate upper limit' % (frachi, med_qhi)\
      + '\n    event spectrum spread    median(abs(raw-med)): %.3f ADU - spectral peak width estimator' % med_abs_dev
    logger.info(s)

    #sys.exit('TEST EXIT')

    logger.debug(info_ndarr(arr_med, '1st iteration proc time = %.3f sec arr_av1' % (time()-t0_sec)))
    #gate_half = nsigma*rms_ave
    #logger.debug('set gate_half=%.3f for intensity gated average, which is %.3f * sigma' % (gate_half,nsigma))
    #gate_half = nsigma*abs_dev_med
    #logger.debug('set gate_half=%.3f for intensity gated average, which is %.3f * abs_dev_med' % (gate_half,nsigma))

    # 2nd loop over recs in block to evaluate gated parameters
    logger.debug('Begin 2nd iteration')

    sta_int_lo = np.zeros(shape, dtype=np.uint64)
    sta_int_hi = np.zeros(shape, dtype=np.uint64)

    arr_max = np.zeros(shape, dtype=block.dtype)
    arr_min = np.ones (shape, dtype=block.dtype) * 0x3fff

    gate_lo    = arr1_u16 * int_lo
    gate_hi    = arr1_u16 * int_hi

    #gate_hi = np.minimum(arr_av1 + gate_half, gate_hi).astype(dtype=block.dtype)
    #gate_lo = np.maximum(arr_av1 - gate_half, gate_lo).astype(dtype=block.dtype)
    gate_lo = np.maximum(arr_qlo, gate_lo).astype(dtype=block.dtype)
    gate_hi = np.minimum(arr_qhi, gate_hi).astype(dtype=block.dtype)
    cond = gate_hi>gate_lo
    gate_hi[np.logical_not(cond)] +=1
    #gate_hi = np.select((cond, np.logical_not(cond)), (gate_hi, gate_hi+1), 0)

    logger.debug(info_ndarr(gate_lo, '    gate_lo '))
    logger.debug(info_ndarr(gate_hi, '    gate_hi '))

    arr_sum0 = np.zeros(shape, dtype=np.uint64)
    arr_sum1 = np.zeros(shape, dtype=np.float64)
    arr_sum2 = np.zeros(shape, dtype=np.float64)

    #blockdbl = np.array(block, dtype=np.float64)

    for nrec in range(nrecs):
        raw    = block[nrec,:]
        rawdbl = raw.astype(dtype=np.uint64) # blockdbl[nrec,:]

        logger.debug('nrec:%03d median(raw-ave): %f' % (nrec, np.median(raw.astype(dtype=np.float64) - arr_med)))
        #logger.debug('nrec:%03d median(raw-ave): %.6f' % (nrec, np.median(raw.astype(dtype=np.float64) - arr_med)))
        #logger.debug(info_ndarr(raw, '  raw     '))
        #logger.debug(info_ndarr(arr_med, '  arr_med '))

        condlist = (np.logical_not(np.logical_or(raw<gate_lo, raw>gate_hi)),)

        arr_sum0 += np.select(condlist, (arr1,), 0)
        arr_sum1 += np.select(condlist, (rawdbl,), 0)
        arr_sum2 += np.select(condlist, (np.square(rawdbl),), 0)

        sta_int_lo += np.select((raw<int_lo,), (arr1,), 0)
        sta_int_hi += np.select((raw>int_hi,), (arr1,), 0)

        arr_max = np.maximum(arr_max, raw)
        arr_min = np.minimum(arr_min, raw)

    arr_av1 = divide_protected(arr_sum1, arr_sum0)
    arr_av2 = divide_protected(arr_sum2, arr_sum0)

    frac_int_lo = np.array(sta_int_lo/nrecs, dtype=np.float32)
    frac_int_hi = np.array(sta_int_hi/nrecs, dtype=np.float32)

    arr_rms = np.sqrt(arr_av2 - np.square(arr_av1))
    #rms_ave = arr_rms.mean()
    rms_ave = mean_constrained(arr_rms, rms_lo, rms_hi)

    rms_min, rms_max = evaluate_limits(arr_rms, rmsnlo, rmsnhi, rms_lo, rms_hi, cmt='RMS')
    ave_min, ave_max = evaluate_limits(arr_av1, intnlo, intnhi, int_lo, int_hi, cmt='AVE')

    arr_sta_rms_hi = np.select((arr_rms>rms_max,),    (arr1,), 0)
    arr_sta_rms_lo = np.select((arr_rms<rms_min,),    (arr1,), 0)
    arr_sta_int_hi = np.select((frac_int_hi>fraclm,), (arr1,), 0)
    arr_sta_int_lo = np.select((frac_int_lo>fraclm,), (arr1,), 0)
    arr_sta_ave_hi = np.select((arr_av1>ave_max,),    (arr1,), 0)
    arr_sta_ave_lo = np.select((arr_av1<ave_min,),    (arr1,), 0)

    logger.info('Bad pixel status:'\
               +'\n  status  1: %8d pixel rms       > %.3f' % (arr_sta_rms_hi.sum(), rms_max)\
               +'\n  status  2: %8d pixel rms       < %.3f' % (arr_sta_rms_lo.sum(), rms_min)\
               +'\n  status  4: %8d pixel intensity > %g in more than %g fraction of events' % (arr_sta_int_hi.sum(), int_hi, fraclm)\
               +'\n  status  8: %8d pixel intensity < %g in more than %g fraction of events' % (arr_sta_int_lo.sum(), int_lo, fraclm)\
               +'\n  status 16: %8d pixel average   > %g'   % (arr_sta_ave_hi.sum(), ave_max)\
               +'\n  status 32: %8d pixel average   < %g'   % (arr_sta_ave_lo.sum(), ave_min)\
               )

    #0/1/2/4/8/16/32 for good/hot-rms/saturated/cold/cold-rms/average above limit/average below limit,
    arr_sta = np.zeros(shape, dtype=np.uint64)
    arr_sta += arr_sta_rms_hi    # hot rms
    arr_sta += arr_sta_rms_lo*2  # cold rms
    arr_sta += arr_sta_int_hi*4  # satturated
    arr_sta += arr_sta_int_lo*8  # cold
    arr_sta += arr_sta_ave_hi*16 # too large average
    arr_sta += arr_sta_ave_lo*32 # too small average

    absdiff_av1_med = np.abs(arr_av1-arr_med)
    logger.debug(info_ndarr(absdiff_av1_med, 'np.abs(arr_av1-arr_med)', first=100, last=105))
    logger.info('estimator of difference between gated average and median np.median(np.abs(arr_av1-arr_med)): %.3f' % np.median(absdiff_av1_med))

    cond = absdiff_av1_med > med_abs_dev
    arr_av1[cond] = arr_med[cond]

    arr_sta_bad = np.select((cond,), (arr1,), 0)
    frac_bad = arr_sta_bad.sum()/float(arr_av1.size)
    logger.debug('fraction of panel pixels with gated average deviated from and replaced by median: %.6f' % frac_bad)

    logger.info('data block processing time = %.3f sec' % (time()-t0_sec))
    logger.debug(info_ndarr(arr_av1, 'arr_av1     [100:105] ', first=100, last=105))
    logger.debug(info_ndarr(arr_rms, 'pixel_rms   [100:105] ', first=100, last=105))
    logger.debug(info_ndarr(arr_sta, 'pixel_status[100:105] ', first=100, last=105))
    logger.debug(info_ndarr(arr_med, 'arr mediane [100:105] ', first=100, last=105))

    return arr_av1, arr_rms, arr_sta


def selected_record(nrec):
    return nrec<5\
       or (nrec<50 and not nrec%10)\
       or (not nrec%100)
       #or (nrec<500 and not nrec%100)\


def print_statistics(nevt, nrec):
    logger.debug('statistics nevt:%d nrec:%d lost frames:%d' % (nevt, nrec, nevt-nrec))


def irun_first(runs):
    """Returns the 1st (int) run number from list or string or int
    """
    return runs[0] if isinstance(runs, list) else\
           runs if isinstance(runs, int) else\
           int(runs.split(',',1)[0].split('-',1)[0])


def data_source_kwargs(**kwa):
    """Makes from input **kwa and returns dict of arguments **kwa for DataSource(**kwa)
    """
    fname      = kwa.get('fname', None)
    detname    = kwa.get('det', None)
    exp        = kwa.get('exp', None)
    runs       = kwa.get('runs', None)
    dirxtc     = kwa.get('dirxtc', None)
    usesmd     = kwa.get('usesmd', False)

    irun = irun_first(runs)

    kwa = {'files':fname} if fname else {'exp':exp,'run':irun}
    if dirxtc: kwa['dir'] = dirxtc
    logger.debug('DataSource **kwargs: %s' % str(kwa))
    #sys.exit('TEST EXIT')
    return kwa


def pedestals_calibration(*args, **kwa):
    """NEWS significant ACCELERATION is acheived:
       - accumulate data for entire epix10kam_2m/quad array
       - use MPI
       all-panel or selected-panel one-step (gain range) or all steps calibration of pedestals
    """
    fname      = kwa.get('fname', None)
    detname    = kwa.get('det', None)
    exp        = kwa.get('exp', None)
    runs       = kwa.get('runs', None)
    nrecs      = kwa.get('nrecs', 1000)
    stepnum    = kwa.get('stepnum', None)
    stepmax    = kwa.get('stepmax', 5)
    evskip     = kwa.get('evskip', 0)
    events     = kwa.get('events', 1000)
    dirxtc     = kwa.get('dirxtc', None)
    dirrepo    = kwa.get('dirrepo', CALIB_REPO_EPIX10KA)
    fmt_peds   = kwa.get('fmt_peds', '%.3f')
    fmt_rms    = kwa.get('fmt_rms',  '%.3f')
    fmt_status = kwa.get('fmt_status', '%4i')
    idx_sel    = kwa.get('idx', None)
    dirmode    = kwa.get('dirmode', 0o777)
    filemode   = kwa.get('filemode', 0o666)
    usesmd     = kwa.get('usesmd', False)
    logmode    = kwa.get('logmode', 'DEBUG')
    errskip    = kwa.get('errskip', False)

    logger.setLevel(DICT_NAME_TO_LEVEL[logmode])

    #irun = runs[0] if isinstance(runs, list) else\
    #       int(runs.split(',',1)[0].split('-',1)[0]) # int first run number from str of run(s)
    irun = irun_first(runs)

    #dsname = 'exp=%s:run=%s'%(exp,runs) if dirxtc is None else 'exp=%s:run=%s:dir=%s'%(exp, runs, dirxtc)
    #if usesmd: dsname += ':smd'

    #_name = sys._getframe().f_code.co_name
    _name = SCRNAME
    logger.info('In %s\n  exp: %s\n  runs: %s\n  detector: %s' % (_name, exp, str(runs), detname))
    save_log_record_at_start(dirrepo, _name, dirmode, filemode, logmode)

    #cpdic = get_config_info_for_dataset_detname(dsname, detname)
    #tstamp      = cpdic.get('tstamp', None)
    #panel_ids   = cpdic.get('panel_ids', None)
    #expnum      = cpdic.get('expnum', None)
    #dettype     = cpdic.get('dettype', None)
    #shape       = cpdic.get('shape', None)
    #ny,nx = shape

    #panel_id = get_panel_id(panel_ids, idx)
    #logger.debug('Found panel ids:\n%s' % ('\n'.join(panel_ids)))

    #read input xtc file and accumulate block of data

    #================= MPI

    #from mpi4py import MPI
    #comm = MPI.COMM_WORLD
    #rank = comm.Get_rank()
    #size = comm.Get_size() # number of MPI nodes; 1 for regular python command

    #=================

    kwa = data_source_kwargs(**kwa)
    #ds = DataSource(**kwa)
    try: ds = DataSource(**kwa)
    except Exception as err:
        logger.error('DataSource(**kwa) does not work:\n    %s' % err)
        sys.exit('EXIT - requested DataSource does not exist or is not accessible.')

    logger.debug('ds.runnum_list = %s' % str(ds.runnum_list))
    logger.debug('ds.detectors = %s' % str(ds.detectors))
    logger.info('ds.xtc_files:\n  %s' % ('\n  '.join(ds.xtc_files)))

    mode = None # gain_mode
    nstep_tot = -1

    #orun = next(ds.runs())
    for orun in ds.runs():
      logger.debug('==run.runnum   : %d' % orun.runnum)        # 27
      logger.debug('  run.detnames : %s' % str(orun.detnames)) # {'epixquad'}
      logger.debug('  run.expt     : %s', orun.expt)           # ueddaq02

      runtstamp = orun.timestamp    # 4193682596073796843 relative to 1990-01-01
      trun_sec = seconds(runtstamp) # 1607569818.532117 sec
      #tstamp = str_tstamp(time_sec=int(trun_sec)) #fmt='%Y-%m-%dT%H:%M:%S%z'

      tstamp_run, tstamp_now = tstamps_run_and_now(int(trun_sec))
      tstamp = tstamp_run

      logger.debug('  run.timestamp: %d' % orun.timestamp)
      logger.debug('  run unix epoch time %06f sec' % trun_sec)
      logger.debug('  run tstamp: %s' % tstamp_run)
      logger.debug('  now tstamp: %s' % tstamp_now)
      det = orun.Detector(detname)
      #step_value = orun.Detector('step_value')
      try: step_docstring = orun.Detector('step_docstring')
      except Exception as err:
        logger.error('run.Detector("step_docstring") does not work:\n    %s' % err)
        sys.exit('Exit processing due to missing info about dark data step.')
      #cd = orun.Detector('ControlData') #LCLS1

      logger.debug('--- det.raw._det_name: %s' % det.raw._det_name) # epixquad
      logger.debug('    det.raw._dettype : %s' % det.raw._dettype)  # epix
      logger.debug('    det.raw._calibconst.keys(): %s' % str(det.raw._calibconst.keys())) # dict_keys(['geometry'])
      #logger.debug('    det.raw._uniqueid: %s' % det.raw._uniqueid)
      #logger.debug('    det.raw._sorted_segment_ids: %s' % str(det.raw._sorted_segment_ids))
      #logger.debug('    det.raw._fullname: %s' % det.raw._fullname())

      segment_ids = det.raw._segment_ids() #ue.segment_ids_det(det)
      segment_inds = det.raw._segment_indices() #ue.segment_indices_det(det)
      s = 'segment inds and ids in the detector'
      for i,id in zip(segment_inds,segment_ids):
          s += '\n  seg:%02d id:%s' % (i,id)
      logger.info(s)

      BIT_MASK = det.raw._data_bit_mask
      logger.info('    det.raw._data_bit_mask BIT_MASK: %s' % oct(BIT_MASK))

      #logger.debug('    det.raw._segment_ids: %s' % str(det.raw._segment_ids()))
      #logger.debug('    det.raw._segment_indices: %s' % str(det.raw._segment_indices()))

      dcfg = det.raw._config_object() #ue.config_object_det(det)

      for nstep_run, step in enumerate(orun.steps()): #(loop through calyb cycles, using only the first):
        nstep_tot += 1
        logger.info('\n=============== step %2d ===============' % nstep_tot)
        logger.debug('    step.evt._seconds: %d' % step.evt._seconds)

        metadic = json.loads(step_docstring(step))
        nstep = step_counter(metadic, nstep_tot, nstep_run, stype='pedestal')

        if nstep is None: continue

        #if size > 1:
        #    # if MPI is on process all steps, step per rank
        #    if nstep < rank: continue
        #    if nstep > rank: break

        if nstep_tot>=stepmax:
            logger.info('==== Step:%02d loop is terminated, --stepmax=%d' % (nstep_tot, stepmax))
            break

        elif stepnum is not None:
            if   nstep < stepnum:
                logger.info('==== Step:%02d is skipped, --stepnum=%d' % (nstep, stepnum))
                continue
            elif nstep > stepnum:
                logger.info('==== Step:%02d loop is terminated, --stepnum=%d' % (nstep, stepnum))
                break

        #for k,v in det.raw._seg_configs().items(): # cpo's pattern DOES NOT WORK
        for k,v in dcfg.items():
            scob = v.config
            logger.info(info_ndarr(scob.asicPixelConfig, 'seg:%02d trbits: %s asicPixelConfig:'%(k, str(scob.trbit))))
            #logger.info(info_ndarr(scob.asicPixelConfig[:,:-2,:], 'seg:%02d trbits: %s asicPixelConfig:'%(k, str(scob.trbit))))

        gmaps = ue.gain_maps_epix10ka_any(det.raw, evt=None) #dcfg, data=None)
        logger.debug('gain mode statistics:' + ue.info_pixel_gain_mode_statistics(gmaps))
        logger.debug(ue.info_pixel_gain_mode_fractions(det.raw, evt=None, msg='gain mode fractions :'))

        logger.debug('gain maps'\
          + info_ndarr(gmaps[0],'\n    FH  ')\
          + info_ndarr(gmaps[1],'\n    FM  ')\
          + info_ndarr(gmaps[2],'\n    FL  ')\
          + info_ndarr(gmaps[3],'\n    AHL ')\
          + info_ndarr(gmaps[4],'\n    AML ')\
        )

        mode = ue.find_gain_mode(det.raw, evt=None).upper()   #dcfg, data=None).upper()

        if mode in ue.GAIN_MODES_IN:
            mode_in_step = ue.GAIN_MODES_IN[nstep]
            logger.info('== step %d: dark run processing for gain mode in configuration %s and step number %s'\
                        %(nstep, mode, mode_in_step))
            if mode != mode_in_step:
              logger.warning('INCONSISTENT GAIN MODES IN CONFIGURATION AND STEP NUMBER/METADATA')
              if not errskip: sys.exit()
              logger.warning('FLAG ERRSKIP IS %s - keep processing assuming gain mode %s' % (errskip,mode))
              #continue
        else:
            logger.warning('UNRECOGNIZED GAIN MODE: %s, DARKS NOT UPDATED...'%mode)
            sys.exit()
            #return

        sh = gmaps[0].shape
        shape_block = [nrecs,] + list(sh) # [nrecs, <number-of-segments>, 352, 384]
        logger.info('Accumulate raw frames in block shape = %s' % str(shape_block))

        block=np.zeros(shape_block,dtype=np.uint16)
        nrec,nevt = -1,0

        ss = None
        for nevt,evt in enumerate(step.events()):
            raw = det.raw.raw(evt)
            do_print = selected_record(nevt)
            if raw is None:
                logger.info('==== Ev:%04d rec:%04d raw is None' % (nevt,nrec))
                continue

            if nevt < evskip:
                logger.debug('==== Ev:%04d is skipped, --evskip=%d' % (nevt,evskip))
                continue
            elif evskip>0 and (nevt == evskip):
                s = 'Events < --evskip=%d are skipped' % evskip
                #print(s)
                logger.info(s)

            if nevt > events-1:
                logger.info(ss)
                logger.info('==== Ev:%04d event loop is terminated, --events=%d' % (nevt,events))
                print()
                break

            if nrec > nrecs-2:
                logger.info(ss)
                logger.info('==== Ev:%04d event loop is terminated - collected sufficient number of frames, --nrecs=%d' % (nevt,nrecs))
                break
            else:
                nrec += 1
                ss = info_ndarr(raw & BIT_MASK, 'Ev:%04d rec:%04d raw & BIT_MASK ' % (nevt,nrec))
                if do_print: logger.info(ss)
                block[nrec]=(raw & BIT_MASK)

        if nevt < events: logger.info('==== Ev:%04d end of events in run step %d' % (nevt,nstep_run))

        print_statistics(nevt, nrec)

        #---- process statistics in block-array for panels

        for idx, panel_id in zip(segment_inds,segment_ids):

            if idx_sel is not None and idx_sel != idx: continue # skip panels with inices other than idx_sel if specified

            logger.info('\n%s\nprocess panel:%02d id:%s' % (96*'=', idx, panel_id))

            #if mode is None:
            #    msg = 'Gain mode for dark processing is not defined "%s" try to set option -m <gain-mode>' % mode
            #    logger.warning(msg)
            #    sys.exit(msg)

            dir_panel, dir_offset, dir_peds, dir_plots, dir_work, dir_gain, dir_rms, dir_status = dir_names(dirrepo, panel_id)

            #print('XXXX panel_id, tstamp, exp, irun', panel_id, tstamp, exp, irun)

            fname_prefix, panel_alias = file_name_prefix(dirrepo, det.raw._dettype, panel_id, tstamp, exp, irun)
            logger.debug('\n  fname_prefix:%s\n  panel_alias :%s' % (fname_prefix, panel_alias))

            prefix_offset, prefix_peds, prefix_plots, prefix_gain, prefix_rms, prefix_status =\
                path_prefixes(fname_prefix, dir_offset, dir_peds, dir_plots, dir_gain, dir_rms, dir_status)

            #logger.debug('Directories under %s\n  SHOULD ALREADY EXIST after charge-injection offset_calibration' % dir_panel)
            #assert os.path.exists(dir_offset), 'Directory "%s" DOES NOT EXIST' % dir_offset
            #assert os.path.exists(dir_peds),   'Directory "%s" DOES NOT EXIST' % dir_peds

            create_directory(dir_panel,  mode=dirmode)
            create_directory(dir_peds,   mode=dirmode)
            create_directory(dir_offset, mode=dirmode)
            create_directory(dir_gain,   mode=dirmode)
            create_directory(dir_rms,    mode=dirmode)
            create_directory(dir_status, mode=dirmode)


            #dark=block[:nrec,:].mean(0)  #Calculate mean

            #block.sahpe = (1024, 16, 352, 384)
            dark, rms, status = proc_dark_block(block[:nrec,idx,:], **kwa) # process pedestals per-panel (352, 384)


            #continue # TEST
            #==========

            fname = '%s_pedestals_%s.dat' % (prefix_peds, mode)
            save_2darray_in_textfile(dark, fname, filemode, fmt_peds)

            fname = '%s_rms_%s.dat' % (prefix_rms, mode)
            save_2darray_in_textfile(rms, fname, filemode, fmt_rms)

            fname = '%s_status_%s.dat' % (prefix_status, mode)
            save_2darray_in_textfile(status, fname, filemode, fmt_status)

            #if this is an auto gain ranging mode, also calculate the corresponding _L pedestal:

            if mode=='AHL-H': # evaluate AHL_L from AHL_H
                ped_hl_h = dark #[3,:,:]

                offset_hl_h = load_panel_constants(dir_offset, 'offset_AHL-H', tstamp)
                offset_hl_l = load_panel_constants(dir_offset, 'offset_AHL-L', tstamp)
                gain_hl_h   = load_panel_constants(dir_gain,   'gainci_AHL-H', tstamp)
                gain_hl_l   = load_panel_constants(dir_gain,   'gainci_AHL-L', tstamp)

                #if offset is not None:
                if all([v is not None for v in (offset_hl_h, offset_hl_l, gain_hl_h, gain_hl_l)]):
                    ped_hl_l = offset_hl_l - (offset_hl_h - ped_hl_h) * divide_protected(gain_hl_l, gain_hl_h) #V3 Gabriel's
                    fname = '%s_pedestals_AHL-L.dat' % prefix_peds
                    save_2darray_in_textfile(ped_hl_l, fname, filemode, fmt_peds)

            elif mode=='AML-M': # evaluate AML_L from AML_M
                ped_ml_m = dark #[4,:,:]

                offset_ml_m = load_panel_constants(dir_offset, 'offset_AML-M', tstamp)
                offset_ml_l = load_panel_constants(dir_offset, 'offset_AML-L', tstamp)
                gain_ml_m   = load_panel_constants(dir_gain,   'gainci_AML-M', tstamp)
                gain_ml_l   = load_panel_constants(dir_gain,   'gainci_AML-L', tstamp)

                #if offset is not None:
                if all([v is not None for v in (offset_ml_m, offset_ml_l, gain_ml_m, gain_ml_l)]):
                    ped_ml_l = offset_ml_l - (offset_ml_m - ped_ml_m) * divide_protected(gain_ml_l, gain_ml_m) #V3 Gabriel's
                    fname = '%s_pedestals_AML-L.dat' % prefix_peds
                    save_2darray_in_textfile(ped_ml_l, fname, filemode, fmt_peds)
    #logger.info('==== Completed pedestal calibration for rank %d ==== ' % rank)


def get_config_info_for_dataset_detname(**kwargs):

    detname = kwargs.get('det', None)
    idx     = kwargs.get('idx', None)

    ds = DataSource(**data_source_kwargs(**kwargs))
    logger.debug('ds.runnum_list = %s' % str(ds.runnum_list))
    logger.debug('ds.detectors = %s' % str(ds.detectors))
    logger.info('ds.xtc_files:\n  %s' % ('\n  '.join(ds.xtc_files)))

    #for orun in ds.runs():
    orun = next(ds.runs())
    if orun:

      logger.debug('==run.runnum   : %d' % orun.runnum)        # 27
      logger.debug('  run.detnames : %s' % str(orun.detnames)) # {'epixquad'}
      logger.debug('  run.expt     : %s', orun.expt)           # ueddaq02

      runtstamp = orun.timestamp    # 4193682596073796843 relative to 1990-01-01
      trun_sec = seconds(runtstamp) # 1607569818.532117 sec
      #tstamp_run = str_tstamp(time_sec=int(trun_sec)) #fmt='%Y-%m-%dT%H:%M:%S%z'
      tstamp_run, tstamp_now = tstamps_run_and_now(int(trun_sec)) # (str) 20201209191018, 20201217140026
      logger.debug('  run.timestamp: %d' % orun.timestamp)
      logger.debug('  run unix epoch time %06f sec' % trun_sec)
      logger.debug('  run tstamp: %s' % tstamp_run)
      logger.debug('  now tstamp: %s' % tstamp_now)

      det = orun.Detector(detname)

      #co = det.raw._config_object()

      cpdic = {}
      cpdic['expname']    = orun.expt
      cpdic['strsrc']     = None
      cpdic['shape']      = det.raw._seg_geo.shape() # (352, 384) for epix10ka or (288,384) for epixhr2x2
      cpdic['gain_mode']  = ue.find_gain_mode(det.raw, evt=None) #data=raw: distinguish 5-modes w/o data
      cpdic['panel_ids']  = det.raw._segment_ids() #ue.segment_ids_det(det)
      cpdic['panel_inds'] = det.raw._segment_indices() #ue.segment_indices_det(det)
      cpdic['longname']   = det.raw._fullname() #ue.fullname_det(det) #det.raw._uniqueid
      cpdic['det_name']   = det._det_name # det.raw._det_name epixquad
      cpdic['dettype']    = det._dettype # epix
      cpdic['tstamp']     = tstamp_run # (str) 20201209191018
      cpdic['tstamp_now'] = tstamp_now # (str) 20201217140026
      cpdic['trun_sec']   = int(trun_sec) # 1607569818.532117 sec
      cpdic['tsrun_dark'] = str_tstamp(time_sec=int(trun_sec)) #fmt='%Y-%m-%dT%H:%M:%S%z'
      cpdic['gains_def']  = det.raw._gains_def # e.g. for epix10ka (16.4, 5.466, 0.164) ADU/keV
      return cpdic


def merge_panel_gain_ranges(dir_ctype, panel_id, ctype, tstamp, shape, dtype, ofname, fmt='%.3f', fac_mode=0o777):

    logger.debug('In merge_panel_gain_ranges for\n  dir_ctype: %s\n  id: %s\n  ctype=%s tstamp=%s shape=%s dtype=%s fmt=%s'%\
                 (dir_ctype, panel_id, ctype, str(tstamp), str(shape), str(dtype), str(fmt)))

    #dtype = np.uint64 if ctype in ('status', ) else np.float32
    nda_def = np.ones(shape, dtype=dtype) if ctype in ('gain', 'gainci', 'rms') else\
              np.zeros(shape, dtype=dtype)

    lstnda = []
    for igm,gm in enumerate(ue.GAIN_MODES):
        fname = None if gm in ue.GAIN_MODES[5:] and ctype in ('status', 'rms') else\
                find_file_for_timestamp(dir_ctype, '%s_%s' % (ctype,gm), tstamp)
        nda = np.loadtxt(fname, dtype=dtype) if fname is not None else\
              nda_def*GAIN_FACTOR_DEF[igm] if ctype in ('gain', 'gainci') else\
              nda_def

        # normalize gains for ctype 'gainci'
        if fname is not None and ctype == 'gainci':
            med_nda = np.median(nda)
            dir_gain = dir_ctype
            if med_nda != 0:
                f_adu_to_kev = 0

                if gm in GAIN_MODES_IN: # 'FH','FM','FL','AHL-H','AML-M' # 'AHL-L','AML-L'
                    f_adu_to_kev = GAIN_FACTOR_DEF[igm] / med_nda
                    nda = nda * f_adu_to_kev

                elif gm=='AHL-L':
                    #gain_hl_l = load_panel_constants(dir_gain, 'gainci_AHL-L', tstamp)
                    gain_hl_h = load_panel_constants(dir_gain, 'gainci_AHL-H', tstamp)
                    if gain_hl_h is None: continue
                    med_hl_h = np.median(gain_hl_h)
                    #V1
                    #ratio_lh = med_nda/med_hl_h if med_hl_h>0 else 0
                    #f_adu_to_kev = ratio_lh * GAIN_FACTOR_DEF[3] / med_nda
                    f_adu_to_kev = GAIN_FACTOR_DEF[3] / med_hl_h if med_hl_h>0 else 0
                    nda *= f_adu_to_kev
                    #V2
                    #nda = GAIN_FACTOR_DEF[3] * divide_protected(nda, gain_hl_h)

                elif gm=='AML-L':
                    #gain_ml_l = load_panel_constants(dir_gain, 'gainci_AML-L', tstamp)
                    gain_ml_m = load_panel_constants(dir_gain, 'gainci_AML-M', tstamp)
                    if gain_ml_m is None: continue
                    med_ml_m = np.median(gain_ml_m)
                    #V1
                    #ratio_lm = med_nda/med_ml_m if med_ml_m>0 else 0
                    #f_adu_to_kev = ratio_lm * GAIN_FACTOR_DEF[4] / med_nda
                    f_adu_to_kev = GAIN_FACTOR_DEF[4] / med_ml_m if med_ml_m>0 else 0
                    nda *= f_adu_to_kev
                    #V2
                    #nda = GAIN_FACTOR_DEF[4] * divide_protected(nda, gain_ml_m)

                    #logger.info('XXXX gm',gm)
                    #logger.info('XXXX med_nda',med_nda)
                    #logger.info('XXXX med_ml_m',med_ml_m)
                    #logger.info('XXXX GAIN_FACTOR_DEF[4]',GAIN_FACTOR_DEF[4])
                    #logger.info('XXXX ratio_lh',ratio_lh)
                    #logger.info('XXXX f_adu_to_kev',f_adu_to_kev)

        lstnda.append(nda if nda is not None else nda_def)
        #logger.debug(info_ndarr(nda, 'nda for %s' % gm))
        #logger.info('%5s : %s' % (gm,fname))

    logger.debug('merge per-gain-range data in segment nda:\n'+'\n'.join([info_ndarr(a,'    ') for a in lstnda]))

    nda = np.stack(tuple(lstnda))
    logger.debug('merge_panel_gain_ranges - merged with shape %s' % str(nda.shape))

    shape_merged = (7, 1) + shape # (7, 1, 352, 384)
    nda.shape = shape_merged
    logger.debug(info_ndarr(nda, 'merged %s'%ctype))
    save_ndarray_in_textfile(nda, ofname, fac_mode, fmt)

    nda.shape = shape_merged # (7, 1, 352, 384) because save_ndarray_in_textfile changes shape
    return nda


def merge_panels(lst):
    """ stack of 16 (or 4 or 1) arrays from list shaped as (7, 1, 352, 384) to (7, 16, 352, 384)
    """
    npanels = len(lst)   # 16 or 4 or 1
    shape = lst[0].shape # (7, 1, 352, 384)
    ngmods = shape[0]    # 7
    dtype = lst[0].dtype #

    logger.debug('In merge_panels: number of panels %d number of gain modes %d dtype %s' % (npanels,ngmods,str(dtype)))

    # make list for merging of (352,384) blocks in right order
    mrg_lst = []
    for igm in range(ngmods):
        nda1gm = np.stack([lst[ind][igm,0,:] for ind in range(npanels)])
        mrg_lst.append(nda1gm)
    return np.stack(mrg_lst)


def add_links_for_gainci_fixed_modes(dir_gain, fname_prefix):
    """FH->AHL-H, FM->AML-M, FL->AML-L/AHL-L"""
    logger.debug('in add_links_for_gainci_fixed_modes, prefix: %s' % (fname_prefix))
    list_of_files = '\n    '.join([name for name in os.listdir(dir_gain)])
    logger.debug('list_of_files in %s:\n    %s' %(dir_gain, list_of_files))

    dic_links = {'FH': 'AHL-H',
                 'FM': 'AML-M',
                 'FL': 'AML-L'} # 'AHL-L'
    for k,v in dic_links.items():
        fname_auto  = '%s/%s_gainci_%s.dat' % (dir_gain, fname_prefix, v)
        fname_fixed = '%s/%s_gainci_%s.dat' % (dir_gain, fname_prefix, k)
        #logger.info('file %s existx %s' % (fname_auto, os.path.exists(fname_auto)))
        if os.path.exists(fname_auto) and not os.path.lexists(fname_fixed):
            os.symlink(os.path.abspath(fname_auto), fname_fixed)
    return


def deploy_constants(*args, **kwa):

    from psana.pscalib.calib.NDArrIO import save_txt; global save_txt
    import psana.pscalib.calib.MDBUtils as mu
    import psana.pscalib.calib.MDBWebUtils as wu
    cc = wu.cc # import psana.pscalib.calib.CalibConstants as cc

    exp        = kwa.get('exp', None)
    detname    = kwa.get('det', None)
    runs       = kwa.get('runs', None)
    tstamp     = kwa.get('tstamp', None) # (int) time stamp in format YYYYmmddHHMMSS or run number(<10000)
    dirxtc     = kwa.get('dirxtc', None)
    dirrepo    = kwa.get('dirrepo', CALIB_REPO_EPIX10KA)
    deploy     = kwa.get('deploy', False)
    fmt_peds   = kwa.get('fmt_peds', '%.3f')
    fmt_gain   = kwa.get('fmt_gain', '%.6f')
    fmt_rms    = kwa.get('fmt_rms',  '%.3f')
    fmt_status = kwa.get('fmt_status', '%4i')
    logmode    = kwa.get('logmode', 'DEBUG')
    dirmode    = kwa.get('dirmode',  0o777)
    filemode   = kwa.get('filemode', 0o666)
    high       = kwa.get('high',   16.40) # ADU/keV
    medium     = kwa.get('medium', 5.466) # ADU/keV
    low        = kwa.get('low',    0.164) # ADU/keV
    proc       = kwa.get('proc', 'prsg')
    paninds    = kwa.get('paninds', None)
    version    = kwa.get('version', 'N/A')
    run_end    = kwa.get('run_end', 'end')
    comment    = kwa.get('comment', 'no comment')
    dbsuffix   = kwa.get('dbsuffix', '')

    logger.setLevel(DICT_NAME_TO_LEVEL[logmode])

    #dsname = 'exp=%s:run=%d'%(exp,irun) if dirxtc is None else 'exp=%s:run=%d:dir=%s'%(exp, irun, dirxtc)
    irun = irun_first(runs)
    #_name = sys._getframe().f_code.co_name
    _name = SCRNAME
    save_log_record_at_start(dirrepo, _name, dirmode, filemode, logmode)

    cpdic = get_config_info_for_dataset_detname(**kwa)
    tstamp_run  = cpdic.get('tstamp',    None) # str
    expnum      = cpdic.get('expnum',    None)
    shape       = cpdic.get('shape',     None)
    strsrc      = cpdic.get('strsrc',    None)
    panel_ids   = cpdic.get('panel_ids', None)
    panel_inds  = cpdic.get('panel_inds',None)
    dettype     = cpdic.get('dettype',   None)
    det_name    = cpdic.get('det_name',  None)
    longname    = cpdic.get('longname', detname)
    gains_def   = cpdic.get('gains_def', None)

    req_inds = None if paninds is None else [int(i) for i in paninds.split(',')] # conv str '0,1,2,3' to list [0,1,2,3]
    logger.info('In %s\n      detector: "%s" \n      requested_inds: %s' % (_name, detname, str(req_inds)))

    assert isinstance(gains_def, tuple)
    assert len(gains_def) == 3

    if high   is None: high   = gains_def[0]
    if medium is None: medium = gains_def[1]
    if low    is None: low    = gains_def[2]

    global GAIN_FACTOR_DEF
    #GAIN_MODES     = ['FH','FM','FL','AHL-H','AML-M','AHL-L','AML-L']
    GAIN_FACTOR_DEF = [high, medium, low, high, medium, low, low]

    CTYPE_FMT = {'pedestals'   : fmt_peds,
                 'pixel_gain'  : fmt_gain,
                 'pixel_rms'   : fmt_rms,
                 'pixel_status': fmt_status}

    CTYPE_DTYPE = cc.dic_calib_name_to_dtype # {'pedestals': np.float32,...}

    logger.debug('detector "%s" panel ids:\n  %s' % (detname, '\n  '.join(panel_ids)))

    #if tstamp is None: tstamp = tstamp_run
    _tstamp = tstamp_run

    logger.debug('search for calibration files with tstamp <= %s' % _tstamp)

    # dict_consts for constants octype: 'pixel_gain', 'pedestals', etc.
    dic_consts = {}
    for ind, panel_id in zip(panel_inds,panel_ids):

        if req_inds is not None and not (ind in req_inds): continue # skip non-selected panels

        logger.info('%s\nmerge constants for panel:%02d id: %s' % (98*'_', ind, panel_id))

        dir_panel, dir_offset, dir_peds, dir_plots, dir_work, dir_gain, dir_rms, dir_status = dir_names(dirrepo, panel_id)
        fname_prefix, panel_alias = file_name_prefix(dirrepo, dettype, panel_id, _tstamp, exp, irun)

        prefix_offset, prefix_peds, prefix_plots, prefix_gain, prefix_rms, prefix_status =\
            path_prefixes(fname_prefix, dir_offset, dir_peds, dir_plots, dir_gain, dir_rms, dir_status)

        #mpars = (('pedestals', 'pedestals',    prefix_peds,   dir_peds),\
        #         ('rms',       'pixel_rms',    prefix_rms,    dir_rms),\
        #         ('status',    'pixel_status', prefix_status, dir_status),\
        #         ('gain',      'pixel_gain',   prefix_gain,   dir_gain))

        mpars = []
        if 'p' in proc: mpars.append(('pedestals', 'pedestals',    prefix_peds,   dir_peds))
        if 'r' in proc: mpars.append(('rms',       'pixel_rms',    prefix_rms,    dir_rms))
        if 's' in proc: mpars.append(('status',    'pixel_status', prefix_status, dir_status))
        if 'g' in proc: mpars.append(('gain',      'pixel_gain',   prefix_gain,   dir_gain))
        if 'c' in proc: mpars.append(('gainci',    'pixel_gain',   prefix_gain,   dir_gain))
        if 'c' in proc:
             add_links_for_gainci_fixed_modes(dir_gain, fname_prefix) # FH->AHL-H, FM->AML-M, FL->AML-L/AHL-L

        for (ctype, octype, prefix, dir_ctype) in mpars:
            fmt = CTYPE_FMT.get(octype,'%.5f')
            nda_dtype = CTYPE_DTYPE.get(octype, np.float32)

            logger.debug('begin merging for ctype:%s, octype:%s, fmt:%s,\n  prefix:%s' % (ctype, octype, fmt, prefix))
            fname = '%s_%s.txt' % (prefix, ctype)
            nda = merge_panel_gain_ranges(dir_ctype, panel_id, ctype, _tstamp, shape, nda_dtype, fname, fmt, filemode)
            if octype in dic_consts: dic_consts[octype].append(nda) # append for panel per ctype
            else:                    dic_consts[octype] = [nda,]

    logger.info('\n%s\nMERGE PANEL CONSTANTS AND DEPLOY THEM\n' % (80*'_'))

    #if deploy:

    dmerge = dir_merge(dirrepo)
    create_directory(dmerge, mode=dirmode)
    fmerge_prefix = fname_prefix_merge(dmerge, detname, _tstamp, exp, irun)

    for octype, lst in dic_consts.items():
        mrg_nda = merge_panels(lst)
        logger.info(info_ndarr(mrg_nda, 'merged constants for %s ' % octype))
        fmerge = '%s-%s.txt' % (fmerge_prefix, octype)
        fmt = CTYPE_FMT.get(octype,'%.5f')
        save_ndarray_in_textfile(mrg_nda, fmerge, filemode, fmt)

        if True: # deploy:

          # check opt "-t" if constants need to be deployed with diffiernt time stamp or run number
          use_external_run = tstamp is not None and tstamp<10000
          use_external_ts  = tstamp is not None and tstamp>9999
          tvalid_sec = time_sec_from_stamp(fmt=cc.TSFORMAT_SHORT, time_stamp=str(tstamp))\
                  if use_external_ts else cpdic.get('trun_sec', None)
          ivalid_run = tstamp if use_external_run else irun\
                  if not use_external_ts else 0

          dtype = 'ndarray'

          kwa = {
            'iofname'    : fmerge,
            'experiment' : exp,
            'ctype'      : octype,
            'dtype'      : dtype,
            'detector'   : detname,
            'detname'    : det_name,
            'longname'   : longname,
            'time_sec'   : tvalid_sec,
            'time_stamp' : str_tstamp(fmt=cc.TSFORMAT, time_sec=int(tvalid_sec)),
            'tsshort'    : str_tstamp(fmt=cc.TSFORMAT_SHORT, time_sec=int(tvalid_sec)),
            'tstamp_orig': cpdic.get('tsrun_dark', None),
            'run'        : ivalid_run,
            'run_end'    : run_end,
            'run_orig'   : irun,
            'version'    : version,
            'comment'    : comment,
            'extpars'    : {'content':'extended parameters dict->json->str',},
            'dettype'    : dettype,
            'dbsuffix'   : dbsuffix
          }

          logger.debug('DEPLOY metadata: %s' % str(kwa))

          data = mu.data_from_file(fmerge, octype, dtype, True)
          logger.debug(info_ndarr(data, 'merged constants loaded from file'))

          if deploy:
            resp = wu.deploy_constants(data, exp, longname, url=cc.URL_KRB, krbheaders=cc.KRBHEADERS, **kwa)
            #id_data_exp, id_data_det, id_doc_exp, id_doc_det = resp if resp is not None

          else:
            logger.warning('TO DEPLOY CONSTANTS ADD OPTION -D')


if __name__ == "__main__":

  def test_pedestals_calibration_epix10ka(tname):
    #print('DATA FILE IS AVAILABLE ON drp-ued-cmp001 ONLY')
    #  fname = '/u2/pcds/pds/ued/ueddaq02/xtc/ueddaq02-r0027-s000-c000.xtc2',\
    #  fname = '/reg/d/psdm/ued/ueddaq02/xtc/ueddaq02-r0027-s000-c000.xtc2',\
    pedestals_calibration(
      fname = '/cds/data/psdm/ued/ueddaq02/xtc/ueddaq02-r0027-s000-c000.xtc2',\
      det     = 'epixquad',\
      exp     = 'ueddaq02',\
      runs    = [27,],\
      nrecs   = 1024,\
      errskip = True,\
      idx     = None,\
      )
      #stepnum = 1,\
      #mode    = 'AML-M',\
      #dirrepo = './work',
      #dirxtc  = DIR_XTC_TEST,\
      #stepnum = 2,\


  def test_offset_calibration_epix10ka(tname):
    print('TBD')


  def test_deploy_constants_epix10ka(tname):
    deploy_constants(
      exp     = 'ueddaq02',\
      det     = 'epixquad',\
      runs    = 27,\
      tstamp  = 20201216000000,\
      dirxtc  = '/cds/data/psdm/ued/ueddaq02/xtc/',\
      deploy  = False)
      #dirrepo = './work',\
    print('TBD')


  SCRNAME = sys.argv[0].rsplit('/')[-1]
  USAGE = 'python %s <test-name>' % SCRNAME\
        + '\n  where <test-name>'\
        + '\n  1: test_offset_calibration_epix10ka - TBD'\
        + '\n  2: test_pedestals_calibration_epix10ka'\
        + '\n  3: test_deploy_constants_epix10ka - TBD'\
        + '\n'

if __name__ == "__main__":
    print(80*'_')
    logging.basicConfig(format='[%(levelname).1s] L%(lineno)04d: %(message)s', level=logging.DEBUG)
    tname = sys.argv[1] if len(sys.argv)>1 else '0'
    if   tname == '1': test_offset_calibration_epix10ka(tname)
    elif tname == '2': test_pedestals_calibration_epix10ka(tname)
    elif tname == '3': test_deploy_constants_epix10ka(tname)
    else:
        print('Usage: %s'%USAGE)
        sys.exit('Not recognized test name: "%s"' % tname)
    sys.exit('End of %s' % sys.argv[0])

# EOF
