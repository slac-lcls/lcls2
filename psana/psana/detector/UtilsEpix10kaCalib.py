"""
Created on Fri May 11 18:25:48 2018
CALIBRATION - TEST PULSES
@author: Gabriel Blaj

2020-12-03 - Mikhail Dubrovin - begin transition to LCLS2
"""
import os
import sys
from time import time
from psana.detector.RepoManager import init_repoman_and_logger, fname_prefix, fname_prefix_merge, calib_file_name
from psana.detector.UtilsLogging import logging  # DICT_NAME_TO_LEVEL, STR_LEVEL_NAMES
logger = logging.getLogger(__name__)

SCRNAME = sys.argv[0].rsplit('/')[-1]

import numpy as np

import json
from psana import DataSource
from psana.detector.dir_root import DIR_REPO_EPIX10KA
from psana.detector.UtilsEpix import FNAME_PANEL_ID_ALIASES, alias_for_id
from psana.detector.Utils import log_rec_at_start, str_tstamp, create_directory, save_textfile, set_file_access_mode, time_sec_from_stamp, get_login, info_dict
from psana.detector.NDArrUtils import info_ndarr, divide_protected, save_2darray_in_textfile, save_ndarray_in_textfile
import psana.detector.UtilsEpix10ka as ue
import psana.detector.UtilsCalib as uc
from psana.detector.utils_psana import seconds, data_source_kwargs, dict_filter
from psana.detector.UtilsLogging import init_file_handler
#import psana.detector.UtilsCalibRepo as ucr

merge_panels = uc.merge_panels


def is_none(par, msg, logger_method=logger.debug):
    resp = par is None
    if resp: logger_method(msg)
    return resp


def find_file_for_timestamp(dirname, pattern, tstamp):
    # list of file names in directory, dirname, containing pattern
    fnames = [name for name in os.listdir(dirname) if os.path.splitext(name)[-1]=='.data' and pattern in name]

    # list of int tstamps
    # !!! here we assume specific name structure generated by file_name_prefix
    itstamps = [int(name.split('-',3)[2]) for name in fnames]

    # reverse-sort int timestamps in the list
    itstamps.sort(key=int,reverse=True)

    # find the nearest to requested timestamp
    for its in itstamps:
        if its <= int(tstamp):
            # find and return the full file name for selected timestamp
            ts = str(its)

            for name in fnames:
                if ts in name:
                     fname = '%s/%s' % (dirname, name)
                     logger.info('  selected %s for %s and %s' % (os.path.basename(fname),pattern,tstamp))
                     return fname

    logger.debug('directory %s' % dirname)
    logger.info('  NOT FOUND file for pattern %s and timestamp <= %s' % (pattern,tstamp))
    return None


def load_panel_constants(dir_ctype, pattern, tstamp):
    fname = find_file_for_timestamp(dir_ctype, pattern, tstamp)
    arr=None
    if fname is not None and os.path.exists(fname):
        arr=np.loadtxt(fname)
        logger.info('Loaded: %s' % fname)
    else:
        logger.debug('file DOES NOT EXIST: %s' % fname)
        logger.debug('DO NOT save save constants for missing files')
    return arr


def dir_names(repoman, panel_id, ctypes=('pixel_offset', 'pedestals', 'plots', 'work', 'pixel_gain',\
                                         'pixel_rms', 'pixel_status', 'pixel_min', 'pixel_max')):
    """Defines structure of subdirectories in calibration repository."""
    dir_panel  = repoman.makedir_panel(panel_id)
    return (dir_panel,) + tuple(repoman.makedir_ctypes(panel_id, ctypes=ctypes))


def path_prefixes(fnprefix, dir_offset, dir_peds, dir_plots, dir_gain, dir_rms, dir_status, dir_min, dir_max):
    return ['%s/%s' % (d, fnprefix) for d in (dir_offset, dir_peds, dir_plots, dir_gain, dir_rms, dir_status, dir_min, dir_max)]


def tstamps_run_and_now(trun_sec): # unix epoch time, e.g. 1607569818.532117 sec
    """DEPRECATED HERE - USE FROM UtilsCalib.py
       Returns (str) tstamp_run, tstamp_now#, e.g. (str) 20201209191018, 20201217140026
    """
    ts_run = str_tstamp(fmt='%Y%m%d%H%M%S', time_sec=trun_sec)
    ts_now = str_tstamp(fmt='%Y%m%d%H%M%S', time_sec=None)
    return ts_run, ts_now


def step_counter(metadata, nstep_tot, nstep_run, stype='pedestal', nspace=None):
    #nspace=7 - for 103 charge injection calib-cycles, =None for 5 dark
    logger.info('step_counter metadata:%s nstep_tot:%d nstep_run:%d stype:%s nspace:%s'%\
                              (metadata, nstep_tot, nstep_run,stype, str(nspace)))
    if not metadata:
        logger.warning('STEP METADATA IS NOT AVAILABLE nstep_tot:%d, nstep_run:%d' % (nstep_tot, nstep_run))
        return nstep_tot

    assert isinstance(metadata, dict), 'UNEXPECTED non-dict DATA TYPE FOR METADATA: %s'%str(type(metadata))

    scantype = metadata['scantype']
    stepnum = int(metadata['step'])

    if scantype != stype:
        logger.warning('UNEXPECTED SCAN TYPE %s' % scantype)
        return None

    if stepnum != nstep_tot:
        s = 'SEQUENTIAL STEP NUMBER nstep_tot:%d, nstep_run:%d' % (nstep_tot, nstep_run)
        s += ' IS NOT CONSISTENT WITH METADATA %s %d' % (scantype, stepnum)
        logger.warning(s)

    return stepnum


def mean_constrained(arr, lo, hi):
    """Evaluates mean value of the input array for values between low and high limits"""
    condlist = (np.logical_not(np.logical_or(arr<lo, arr>hi)),)
    arr1 = np.ones(arr.shape, dtype=np.int32)
    arr_of1 = np.select(condlist, (arr1,), 0)
    arr_ofv = np.select(condlist, (arr,), 0)
    ngood = arr_of1.sum()
    return arr_ofv.sum()/ngood if ngood else None


def evaluate_limits(arr, nneg=5, npos=5, lim_lo=1, lim_hi=16000, cmt=''):
    """DEPRECATED HERE - USE FROM UtilsCalib.py
       Evaluates low and high limit of the array, which are used to find bad pixels.
    """
    ave, std = (arr.mean(), arr.std()) if (nneg>0 or npos>0) else (None,None)
    lo = ave-nneg*std if nneg>0 else lim_lo
    hi = ave+npos*std if npos>0 else lim_hi
    lo, hi = max(lo, lim_lo), min(hi, lim_hi)

    logger.debug('  %s: %s ave, std = %.3f, %.3f  low, high limits = %.3f, %.3f'%\
                 (sys._getframe().f_code.co_name, cmt, ave, std, lo, hi))
    return lo, hi


def proc_dark_block(block, **kwa):
    """DEPRECATED HERE - USE proc_block FROM UtilsCalib.py
       Returns per-panel (352, 384) arrays of mean, rms, ...
       block.shape = (nrecs, 352, 384), where nrecs <= 1024
    """
    exp        = kwa.get('exp', None)
    detname    = kwa.get('det', None)
    int_lo     = kwa.get('int_lo', 1)       # lowest  intensity accepted for dark evaluation
    int_hi     = kwa.get('int_hi', 16000)   # highest intensity accepted for dark evaluation
    intnlo     = kwa.get('intnlo', 6.0)     # intensity ditribution number-of-sigmas low
    intnhi     = kwa.get('intnhi', 6.0)     # intensity ditribution number-of-sigmas high
    rms_lo     = kwa.get('rms_lo', 0.001)   # rms ditribution low
    rms_hi     = kwa.get('rms_hi', 16000)   # rms ditribution high
    rmsnlo     = kwa.get('rmsnlo', 6.0)     # rms ditribution number-of-sigmas low
    rmsnhi     = kwa.get('rmsnhi', 6.0)     # rms ditribution number-of-sigmas high
    fraclm     = kwa.get('fraclm', 0.1)     # allowed fraction limit
    fraclo     = kwa.get('fraclo', 0.05)    # fraction of statistics below low gate limit
    frachi     = kwa.get('frachi', 0.95)    # fraction of statistics below high gate limit
    frac05     = 0.5
    nrecs1     = kwa.get('nrecs1', None)    # number of records for the 1st stage processing

    logger.debug('in proc_dark_block for exp=%s det=%s, block.shape=%s' % (exp, detname, str(block.shape)))
    logger.info(info_ndarr(block, 'Begin processing of the data block:\n    ', first=100, last=105))
    logger.debug('fraction of statistics for gate limits low: %.3f high: %.3f' % (fraclo, frachi))

    t0_sec = time()

    nrecs, ny, nx = block.shape
    shape = (ny, nx)
    if nrecs1 is None or nrecs1>nrecs: nrecs1 = nrecs

    arr1_u16 = np.ones(shape, dtype=np.uint16)
    arr1     = np.ones(shape, dtype=np.uint64)

    t1_sec = time()

    """
    NOTE:
    - our data is uint16.
    - np.median(block, axis=0) or np.quantile(...,method='linear') return result rounded to int
    - in order to return interpolated float values apply the trick:
      data_block + random [0,1)-0.5
    - this would distort data in the range [-0.5,+0.5) ADU, but would allow to get better interpolation for median and quantile values
    - use nrecs1 (< nrecs) due to memory and time consumption
    """
    #blockf64 = np.random.random(block.shape) - 0.5 + block
    blockf64 = np.random.random((nrecs1, ny, nx)) - 0.5 + block[:nrecs1,:]
    logger.debug(info_ndarr(blockf64, '1-st stage conversion uint16 to float64, add random [0,1)-0.5 time = %.3f sec '%(time()-t1_sec), first=100, last=105))

    t1_sec = time()
    #arr_med = np.median(block, axis=0)
    arr_med = np.quantile(blockf64, frac05, axis=0, method='linear')
    arr_qlo = np.quantile(blockf64, fraclo, axis=0, method='linear')
    arr_qhi = np.quantile(blockf64, frachi, axis=0, method='linear')
    logger.debug('block array median/quantile(0.5) for med, qlo, qhi time = %.3f sec' % (time()-t1_sec))

    med_med = np.median(arr_med)
    med_qlo = np.median(arr_qlo)
    med_qhi = np.median(arr_qhi)

    arr_dev_3d = block[:,] - arr_med # .astype(dtype=np.float64)
    arr_abs_dev = np.median(np.abs(arr_dev_3d), axis=0)
    med_abs_dev = np.median(arr_abs_dev)

    logger.info(info_ndarr(arr_med,     '    arr_med[100:105] ', first=100, last=105))
    logger.info(info_ndarr(arr_qlo,     '    arr_qlo[100:105] ', first=100, last=105))
    logger.info(info_ndarr(arr_qhi,     '    arr_qhi[100:105] ', first=100, last=105))
    logger.info(info_ndarr(arr_abs_dev, '    abs_dev[100:105] ', first=100, last=105))

    s = 'Pre-processing time %.3f sec' % (time()-t0_sec)\
      + '\nResults for median over pixels intensities:'\
      + '\n    %.3f fraction of the event spectrum is below %.3f ADU - pedestal estimator' % (frac05, med_med)\
      + '\n    %.3f fraction of the event spectrum is below %.3f ADU - gate low limit' % (fraclo, med_qlo)\
      + '\n    %.3f fraction of the event spectrum is below %.3f ADU - gate upper limit' % (frachi, med_qhi)\
      + '\n    event spectrum spread    median(abs(raw-med)): %.3f ADU - spectral peak width estimator' % med_abs_dev
    logger.info(s)

    logger.debug(info_ndarr(arr_med, '1st iteration proc time = %.3f sec arr_av1' % (time()-t0_sec)))

    # 2nd loop over recs in block to evaluate gated parameters
    logger.debug('Begin 2nd iteration')

    sta_int_lo = np.zeros(shape, dtype=np.uint64)
    sta_int_hi = np.zeros(shape, dtype=np.uint64)

    arr_max = np.zeros(shape, dtype=block.dtype)
    arr_min = np.ones (shape, dtype=block.dtype) * 0x3fff

    gate_lo    = arr1_u16 * int_lo
    gate_hi    = arr1_u16 * int_hi

    gate_lo = np.maximum(arr_qlo, gate_lo).astype(dtype=block.dtype)
    gate_hi = np.minimum(arr_qhi, gate_hi).astype(dtype=block.dtype)
    cond = gate_hi>gate_lo
    gate_hi[np.logical_not(cond)] +=1

    logger.debug(info_ndarr(gate_lo, '    gate_lo '))
    logger.debug(info_ndarr(gate_hi, '    gate_hi '))

    arr_sum0 = np.zeros(shape, dtype=np.uint64)
    arr_sum1 = np.zeros(shape, dtype=np.float64)
    arr_sum2 = np.zeros(shape, dtype=np.float64)

    for nrec in range(nrecs):
        raw    = block[nrec,:]
        rawdbl = raw.astype(dtype=np.uint64) # blockdbl[nrec,:]

        logger.debug('nrec:%03d median(raw-ave): %f' % (nrec, np.median(raw.astype(dtype=np.float64) - arr_med)))

        condlist = (np.logical_not(np.logical_or(raw<gate_lo, raw>gate_hi)),)

        arr_sum0 += np.select(condlist, (arr1,), 0)
        arr_sum1 += np.select(condlist, (rawdbl,), 0)
        arr_sum2 += np.select(condlist, (np.square(rawdbl),), 0)

        sta_int_lo += np.select((raw<int_lo,), (arr1,), 0)
        sta_int_hi += np.select((raw>int_hi,), (arr1,), 0)

        arr_max = np.maximum(arr_max, raw)
        arr_min = np.minimum(arr_min, raw)

    arr_av1 = divide_protected(arr_sum1, arr_sum0)
    arr_av2 = divide_protected(arr_sum2, arr_sum0)

    nevlm = int(fraclm * nrecs)

    arr_rms = np.sqrt(arr_av2 - np.square(arr_av1))
    #rms_ave = arr_rms.mean()
    rms_ave = mean_constrained(arr_rms, rms_lo, rms_hi)

    rms_min, rms_max = evaluate_limits(arr_rms, rmsnlo, rmsnhi, rms_lo, rms_hi, cmt='RMS')
    ave_min, ave_max = evaluate_limits(arr_av1, intnlo, intnhi, int_lo, int_hi, cmt='AVE')

    arr_sta_rms_hi = np.select((arr_rms>rms_max,),  (arr1,), 0)
    arr_sta_rms_lo = np.select((arr_rms<rms_min,),  (arr1,), 0)
    arr_sta_int_hi = np.select((sta_int_hi>nevlm,), (arr1,), 0)
    arr_sta_int_lo = np.select((sta_int_lo>nevlm,), (arr1,), 0)
    arr_sta_ave_hi = np.select((arr_av1>ave_max,),  (arr1,), 0)
    arr_sta_ave_lo = np.select((arr_av1<ave_min,),  (arr1,), 0)

    logger.info('Bad pixel status:'\
               +'\n  status  1: %8d pixel rms       > %.3f' % (arr_sta_rms_hi.sum(), rms_max)\
               +'\n  status  2: %8d pixel rms       < %.3f' % (arr_sta_rms_lo.sum(), rms_min)\
               +'\n  status  4: %8d pixel intensity > %g in more than %g fraction (%d/%d) of non-empty events'%\
                     (arr_sta_int_hi.sum(), int_hi, fraclm, nevlm, nrecs)\
               +'\n  status  8: %8d pixel intensity < %g in more than %g fraction (%d/%d) of non-empty events'%\
                     (arr_sta_int_lo.sum(), int_lo, fraclm, nevlm, nrecs)\
               +'\n  status 16: %8d pixel average   > %g'   % (arr_sta_ave_hi.sum(), ave_max)\
               +'\n  status 32: %8d pixel average   < %g'   % (arr_sta_ave_lo.sum(), ave_min)\
               )

    #0/1/2/4/8/16/32 for good/hot-rms/saturated/cold/cold-rms/average above limit/average below limit,
    arr_sta = np.zeros(shape, dtype=np.uint64)
    arr_sta += arr_sta_rms_hi    # hot rms
    arr_sta += arr_sta_rms_lo*2  # cold rms
    arr_sta += arr_sta_int_hi*4  # satturated
    arr_sta += arr_sta_int_lo*8  # cold
    arr_sta += arr_sta_ave_hi*16 # too large average
    arr_sta += arr_sta_ave_lo*32 # too small average

    absdiff_av1_med = np.abs(arr_av1-arr_med)
    logger.debug(info_ndarr(absdiff_av1_med, 'np.abs(arr_av1-arr_med)', first=100, last=105))
    logger.info('estimator of difference between gated average and median np.median(np.abs(arr_av1-arr_med)): %.3f' % np.median(absdiff_av1_med))

    cond = absdiff_av1_med > med_abs_dev
    arr_av1[cond] = arr_med[cond]

    arr_sta_bad = np.select((cond,), (arr1,), 0)
    frac_bad = arr_sta_bad.sum()/float(arr_av1.size)
    logger.debug('fraction of panel pixels with gated average deviated from and replaced by median: %.6f' % frac_bad)

    logger.info('data block processing time = %.3f sec' % (time()-t0_sec))
    logger.debug(info_ndarr(arr_av1, 'arr_av1     [100:105] ', first=100, last=105))
    logger.debug(info_ndarr(arr_rms, 'pixel_rms   [100:105] ', first=100, last=105))
    logger.debug(info_ndarr(arr_sta, 'pixel_status[100:105] ', first=100, last=105))
    logger.debug(info_ndarr(arr_med, 'arr mediane [100:105] ', first=100, last=105))
    logger.debug(info_ndarr(arr_min, 'arr minimum [100:105] ', first=100, last=105))
    logger.debug(info_ndarr(arr_max, 'arr maximum [100:105] ', first=100, last=105))

    return arr_av1, arr_rms, arr_sta, arr_min, arr_max


def selected_record(nrec):
    return nrec<5\
       or (nrec<50 and not nrec%10)\
       or (not nrec%100)


def print_statistics(nevt, nrec):
    logger.debug('statistics nevt:%d nrec:%d lost frames:%d' % (nevt, nrec, nevt-nrec))


def irun_first(runs):
    """Returns the 1st (int) run number from list or string or int."""
    return runs[0] if isinstance(runs, list) else\
           runs if isinstance(runs, int) else\
           int(runs.split(',',1)[0].split('-',1)[0])


def pedestals_calibration(parser):
    """NEWS significant ACCELERATION is acheived:
       - accumulate data for entire epix10kam_2m/quad array
       - use MPI
       all-panel or selected-panel one-step (gain range) or all steps calibration of pedestals
    """
    args = parser.parse_args()
    kwa = vars(args)
    repoman = init_repoman_and_logger(parser=parser, **kwa)

    str_dskwargs = kwa.get('dskwargs', None)
    detname    = kwa.get('det', None)
    nrecs      = kwa.get('nrecs', 1000)
    stepnum    = kwa.get('stepnum', None)
    stepmax    = kwa.get('stepmax', 5)
    evskip     = kwa.get('evskip', 0)
    events     = kwa.get('events', 1000)
    dirrepo    = kwa.get('dirrepo', DIR_REPO_EPIX10KA)
    fmt_peds   = kwa.get('fmt_peds', '%.3f')
    fmt_rms    = kwa.get('fmt_rms',  '%.3f')
    fmt_status = kwa.get('fmt_status', '%4i')
    fmt_min    = kwa.get('fmt_min', '%i')
    fmt_max    = kwa.get('fmt_max', '%i')
    idx_sel    = kwa.get('idx', None)
    dirmode    = kwa.get('dirmode', 0o2775)
    filemode   = kwa.get('filemode', 0o664)
    group      = kwa.get('group', 'ps-users')
    logmode    = kwa.get('logmode', 'DEBUG')
    errskip    = kwa.get('errskip', False)
    irun       = None
    exp        = None
    dettype    = None

    dskwargs = data_source_kwargs(**kwa)
    #dskwargs = {'exp': 'ued1011059', 'run': 3, 'dir': '/sdf/data/lcls/ds/ued/ued1011059/xtc', 'detectors': ['epixquad',]} # then  'step_docstring' does not work!
    #dskwargs = {'exp': 'ued1011059', 'run': 3, 'dir': '/sdf/data/lcls/ds/ued/ued1011059/xtc', 'detectors': []}
    #dskwargs = {'exp': 'ued1011059', 'run': 3, 'dir': '/sdf/data/lcls/ds/ued/ued1011059/xtc'}
    logger.info('dskwargs: %s' % str(dskwargs))

    try: ds = DataSource(**dskwargs)
    except Exception as err:
        logger.error('DataSource(**dskwargs) does not work for **dskwargs: %s\n    %s' % (dskwargs, err))
        sys.exit('EXIT - requested DataSource does not exist or is not accessible.')

    logger.debug('ds.runnum_list = %s' % str(ds.runnum_list))
    logger.debug('ds.detectors = %s' % str(ds.detectors))
    xtc_files = getattr(ds, 'xtc_files', None)
    logger.info('ds.xtc_files:\n  %s' % ('None' if xtc_files is None else '\n  '.join(ds.xtc_files)))

    mode = None # gain_mode
    nstep_tot = -1

    #orun = next(ds.runs())
    for orun in ds.runs():
      logger.debug('==run.runnum   : %d' % orun.runnum)        # 27
      logger.debug('  run.detnames : %s' % str(orun.detnames)) # {'epixquad'}
      logger.debug('  run.expt     : %s', orun.expt)           # ueddaq02

      if irun is None: irun = orun.runnum
      if exp is None: exp = orun.expt

      runtstamp = orun.timestamp    # 4193682596073796843 relative to 1990-01-01
      trun_sec = seconds(runtstamp) # 1607569818.532117 sec
      #tstamp = str_tstamp(time_sec=int(trun_sec)) #fmt='%Y-%m-%dT%H:%M:%S%z'

      tstamp_run, tstamp_now = tstamps_run_and_now(int(trun_sec))
      tstamp = tstamp_run

      logger.debug('  run.timestamp: %d' % orun.timestamp)
      logger.debug('  run unix epoch time %06f sec' % trun_sec)
      logger.debug('  run tstamp: %s' % tstamp_run)
      logger.debug('  now tstamp: %s' % tstamp_now)
      odet = orun.Detector(detname)
      longname = odet.raw._uniqueid
      shortname = uc.detector_name_short(longname)

      if dettype is None:
        dettype = odet.raw._dettype
        repoman.set_dettype(dettype)

      #step_value = orun.Detector('step_value')
      try: step_docstring = orun.Detector('step_docstring')
      except Exception as err:
        logger.error('run.Detector("step_docstring") does not work:\n    %s' % err)
        sys.exit('Exit processing due to missing info about dark data step.')
      #cd = orun.Detector('ControlData') #LCLS1

      logger.info('--- det.raw._det_name: %s' % odet.raw._det_name) # epixquad
      logger.info('    det.raw._dettype : %s' % odet.raw._dettype)  # epix
      #logger.debug('    det.raw._uniqueid: %s' % det.raw._uniqueid)
      #logger.debug('    det.raw._sorted_segment_inds: %s' % str(odet.raw._sorted_segment_inds))
      #logger.debug('    det.raw._fullname: %s' % odet.raw._fullname())

      segment_ids = odet.raw._segment_ids() #ue.segment_ids_det(odet)
      segment_inds = odet.raw._segment_indices() #ue.segment_indices_det(odet)
      s = 'segment inds and ids in the detector'
      for i,id in zip(segment_inds,segment_ids):
          s += '\n  seg:%02d id:%s' % (i,id)
      logger.info(s)

      BIT_MASK = odet.raw._data_bit_mask
      BIT_GAIN = odet.raw._data_gain_bit
      logger.info('    det.raw._data_bit_mask BIT_MASK: %d or %s or %s' % (BIT_MASK, oct(BIT_MASK), hex(BIT_MASK)))
      logger.info('    det.raw._data_gain_bit BIT_GAIN: %d or %s or %s' % (BIT_GAIN, oct(BIT_GAIN), hex(BIT_GAIN)))

      dcfg = odet.raw._config_object() #ue.config_object_det(odet)

      for nstep_run, step in enumerate(orun.steps()): #(loop through calyb cycles, using only the first):
        nstep_tot += 1
        logger.info('\n=============== step %2d ===============' % nstep_tot)
        logger.debug('    step.evt._seconds: %d' % step.evt._seconds)

        metadic = json.loads(step_docstring(step))
        nstep = step_counter(metadic, nstep_tot, nstep_run, stype='pedestal')

        if is_none(nstep, 'step is unknown, None', logger_method=logger.info): continue

        if nstep_tot>=stepmax:
            logger.info('==== Step:%02d loop is terminated, --stepmax=%d' % (nstep_tot, stepmax))
            break

        elif stepnum is not None:
            if   nstep < stepnum:
                logger.info('==== Step:%02d is skipped, --stepnum=%d' % (nstep, stepnum))
                continue
            elif nstep > stepnum:
                logger.info('==== Step:%02d loop is terminated, --stepnum=%d' % (nstep, stepnum))
                break

        for k,v in dcfg.items():
            scob = v.config
            logger.info(info_ndarr(scob.asicPixelConfig, 'seg:%02d trbits: %s asicPixelConfig:'%(k, str(scob.trbit))))
            #logger.info(info_ndarr(scob.asicPixelConfig[:,:-2,:], 'seg:%02d trbits: %s asicPixelConfig:'%(k, str(scob.trbit))))

        gmaps = ue.gain_maps_epix10ka_any(odet.raw, evt=None) #dcfg, data=None)
        logger.debug('gain mode statistics:' + ue.info_pixel_gain_mode_statistics(gmaps))
        logger.debug(ue.info_pixel_gain_mode_fractions(odet.raw, evt=None, msg='gain mode fractions :'))

        logger.debug('gain maps'\
          + info_ndarr(gmaps[0],'\n    FH  ')\
          + info_ndarr(gmaps[1],'\n    FM  ')\
          + info_ndarr(gmaps[2],'\n    FL  ')\
          + info_ndarr(gmaps[3],'\n    AHL ')\
          + info_ndarr(gmaps[4],'\n    AML ')\
        )

        mode = ue.find_gain_mode(odet.raw, evt=None).upper()   #dcfg, data=None).upper()

        if mode in ue.GAIN_MODES_IN:
            mode_in_step = ue.GAIN_MODES_IN[nstep]
            logger.info('== step %d: dark run processing for gain mode in configuration %s and step number %s'\
                        %(nstep, mode, mode_in_step))
            if mode != mode_in_step:
              logger.warning('INCONSISTENT GAIN MODES IN CONFIGURATION AND STEP NUMBER/METADATA')
              if not errskip: sys.exit()
              logger.warning('FLAG ERRSKIP IS %s - keep processing assuming gain mode %s' % (errskip,mode))
              #continue
        else:
            logger.warning('UNRECOGNIZED GAIN MODE: %s, DARKS NOT UPDATED...'%mode)
            sys.exit()
            #return

        sh = gmaps[0].shape
        shape_block = [nrecs,] + list(sh) # [nrecs, <number-of-segments>, 352, 384]
        logger.info('Accumulate raw frames in block shape = %s' % str(shape_block))

        block=np.zeros(shape_block,dtype=np.uint16)
        nrec,nevt = -1,0

        ss = None
        counter = 0
        counter_max = 60
        for nevt,evt in enumerate(step.events()):
            raw = odet.raw.raw(evt)
            do_print = selected_record(nevt)
            if raw is None:
                counter += 1
                if counter < counter_max:
                    logger.info('==== Ev:%04d rec:%04d raw is None' % (nevt,nrec))
                elif counter == counter_max:
                    logger.info('==== DO NOT SHOW MORE MESSAGES THAT raw is None')
                continue

            if nevt < evskip:
                logger.debug('==== Ev:%04d is skipped, --evskip=%d' % (nevt,evskip))
                continue
            elif evskip>0 and (nevt == evskip):
                s = 'Events < --evskip=%d are skipped' % evskip
                #print(s)
                logger.info(s)

            if nevt > events-1:
                logger.info(ss)
                logger.info('==== Ev:%04d event loop is terminated, --events=%d' % (nevt,events))
                print()
                break

            if nrec > nrecs-2:
                logger.info(ss)
                logger.info('==== Ev:%04d event loop is terminated - collected sufficient number of frames, --nrecs=%d' % (nevt,nrecs))
                break
            else:
                nrec += 1
                ss = info_ndarr(raw & BIT_MASK, 'Ev:%04d rec:%04d raw & BIT_MASK ' % (nevt,nrec))
                if do_print: logger.info(ss)
                block[nrec]=(raw & BIT_MASK)

        if nevt < events: logger.info('==== Ev:%04d end of events in run step %d' % (nevt,nstep_run))

        print_statistics(nevt, nrec)

        #---- process statistics in block-array for panels

        for idx, panel_id in zip(segment_inds,segment_ids):

            if idx_sel is not None and idx_sel != idx: continue # skip panels with indices other than idx_sel if specified

            logger.info('\n%s\nprocess panel:%02d id:%s' % (96*'=', idx, panel_id))

            dir_panel, dir_offset, dir_peds, dir_plots, dir_work, dir_gain, dir_rms, dir_status, dir_min, dir_max =\
                dir_names(repoman, panel_id)

            fnprefix = fname_prefix(shortname, idx, tstamp_run, orun.expt, orun.runnum, dirname=None)
              # <dirname>/jungfrauemu_000001-s00-20250203095124-mfxdaq23-r0007
            logger.debug('\n  fname_prefix:%s' % fnprefix)

            prefix_offset, prefix_peds, prefix_plots, prefix_gain, prefix_rms, prefix_status, prefix_min, prefix_max =\
                path_prefixes(fnprefix, dir_offset, dir_peds, dir_plots, dir_gain, dir_rms, dir_status, dir_min, dir_max)

            create_directory(dir_panel,  mode=dirmode)
            create_directory(dir_peds,   mode=dirmode)
            create_directory(dir_offset, mode=dirmode)
            create_directory(dir_gain,   mode=dirmode)
            create_directory(dir_rms,    mode=dirmode)
            create_directory(dir_status, mode=dirmode)
            create_directory(dir_min,    mode=dirmode)
            create_directory(dir_max,    mode=dirmode)

            #block.sahpe = (1024, 16, 352, 384)
            int_hi = kwa.get('int_hi', None)
            rms_hi = kwa.get('rms_hi', None)
            kwa['int_hi'] = BIT_MASK-1 if int_hi is None else int_hi
            kwa['rms_hi'] = BIT_MASK-1 if rms_hi is None else rms_hi
            dark, rms, status, arrmin, arrmax = proc_dark_block(block[:nrec,idx,:], **kwa) # process pedestals per-panel (352, 384)


            fname = calib_file_name(prefix_peds, 'pedestals', mode)
            save_2darray_in_textfile(dark, fname, filemode, fmt_peds, logmethod=logger.info)

            fname = calib_file_name(prefix_rms, 'pixel_rms', mode)
            save_2darray_in_textfile(rms, fname, filemode, fmt_rms, logmethod=logger.info)

            fname = calib_file_name(prefix_min, 'pixel_min', mode)
            save_2darray_in_textfile(arrmin, fname, filemode, fmt_min, logmethod=logger.info)

            fname = calib_file_name(prefix_max, 'pixel_max', mode)
            save_2darray_in_textfile(arrmax, fname, filemode, fmt_max, logmethod=logger.info)

            fname = calib_file_name(prefix_status, 'pixel_status', mode)
            save_2darray_in_textfile(status, fname, filemode, fmt_status, logmethod=logger.info)

            #if this is an auto gain ranging mode, also calculate the corresponding _L pedestal:

            if mode=='AHL_H': # evaluate AHL_L from AHL_H
                ped_hl_h = dark #[3,:,:]

                offset_hl_h = load_panel_constants(dir_offset, 'pixel_offset-AHL_H', tstamp)
                offset_hl_l = load_panel_constants(dir_offset, 'pixel_offset-AHL_L', tstamp)
                gain_hl_h   = load_panel_constants(dir_gain,   'pixel_gainci-AHL_H', tstamp)
                gain_hl_l   = load_panel_constants(dir_gain,   'pixel_gainci-AHL_L', tstamp)

                #if offset is not None:
                if all([v is not None for v in (offset_hl_h, offset_hl_l, gain_hl_h, gain_hl_l)]):
                    ped_hl_l = offset_hl_l - (offset_hl_h - ped_hl_h) * divide_protected(gain_hl_l, gain_hl_h) #V3 Gabriel's
                    fname = calib_file_name(prefix_peds, 'pedestals', 'AHL_L')
                    save_2darray_in_textfile(ped_hl_l, fname, filemode, fmt_peds, logmethod=logger.info)

            elif mode=='AML_M': # evaluate AML_L from AML_M
                ped_ml_m = dark #[4,:,:]

                offset_ml_m = load_panel_constants(dir_offset, 'pixel_offset-AML_M', tstamp)
                offset_ml_l = load_panel_constants(dir_offset, 'pixel_offset-AML_L', tstamp)
                gain_ml_m   = load_panel_constants(dir_gain,   'pixel_gainci-AML_M', tstamp)
                gain_ml_l   = load_panel_constants(dir_gain,   'pixel_gainci-AML_L', tstamp)

                #if offset is not None:
                if all([v is not None for v in (offset_ml_m, offset_ml_l, gain_ml_m, gain_ml_l)]):
                    ped_ml_l = offset_ml_l - (offset_ml_m - ped_ml_m) * divide_protected(gain_ml_l, gain_ml_m) #V3 Gabriel's
                    fname = calib_file_name(prefix_peds, 'pedestals', 'AML_L')
                    save_2darray_in_textfile(ped_ml_l, fname, filemode, fmt_peds, logmethod=logger.info)
    #logger.info('==== Completed pedestal calibration for rank %d ==== ' % rank)
    repoman.logfile_save()


def get_config_info_for_dataset_detname(**kwargs):

    detname = kwargs.get('det', None)
    idx     = kwargs.get('idx', None)

    ds = DataSource(**data_source_kwargs(**kwargs))
    logger.debug('ds.runnum_list = %s' % str(ds.runnum_list))
    logger.debug('ds.detectors = %s' % str(ds.detectors))
    logger.debug('ds.xtc_files:\n  %s' % ('\n  '.join(ds.xtc_files)))

    #for orun in ds.runs():
    orun = next(ds.runs())
    if orun:

      logger.debug('==run.runnum   : %d' % orun.runnum)        # 27
      logger.debug('  run.detnames : %s' % str(orun.detnames)) # {'epixquad'}
      logger.debug('  run.expt     : %s', orun.expt)           # ueddaq02

      runtstamp = orun.timestamp    # 4193682596073796843 relative to 1990-01-01
      trun_sec = seconds(runtstamp) # 1607569818.532117 sec
      #tstamp_run = str_tstamp(time_sec=int(trun_sec)) #fmt='%Y-%m-%dT%H:%M:%S%z'
      tstamp_run, tstamp_now = tstamps_run_and_now(int(trun_sec)) # (str) 20201209191018, 20201217140026
      logger.debug('  run.timestamp: %d' % orun.timestamp)
      logger.debug('  run unix epoch time %06f sec' % trun_sec)
      logger.debug('  run tstamp: %s' % tstamp_run)
      logger.debug('  now tstamp: %s' % tstamp_now)

      odet = orun.Detector(detname)

      #co = odet.raw._config_object()

      longname = odet.raw._fullname() #ue.fullname_det(odet) #odet.raw._uniqueid

      cpdic = {}
      cpdic['expname']    = orun.expt   # experiment name
      cpdic['strsrc']     = None
      cpdic['shape']      = odet.raw._seg_geo.shape() # (352, 384) for epix10ka or (288,384) for epixhr2x2 or (144,768) for epixhremu
      cpdic['gain_mode']  = ue.find_gain_mode(odet.raw, evt=None) #data=raw: distinguish 5-modes w/o data
      cpdic['panel_ids']  = odet.raw._segment_ids() #ue.segment_ids_det(odet)
      cpdic['panel_inds'] = odet.raw._segment_indices() #ue.segment_indices_det(odet)
      cpdic['longname']   = longname
      cpdic['shortname']  = uc.detector_name_short(longname)
      cpdic['det_name']   = odet._det_name # odet.raw._det_name epixquad
      cpdic['dettype']    = odet._dettype # epix
      cpdic['tstamp']     = tstamp_run # (str) 20201209191018
      cpdic['tstamp_now'] = tstamp_now # (str) 20201217140026
      cpdic['trun_sec']   = int(trun_sec) # 1607569818.532117 sec
      cpdic['tsrun_dark'] = str_tstamp(time_sec=int(trun_sec)) #fmt='%Y-%m-%dT%H:%M:%S%z'
      cpdic['gains_def']  = odet.raw._gains_def # e.g. for epix10ka (16.4, 5.466, 0.164) ADU/keV
      cpdic['runnum']     = orun.runnum   # run number
      return cpdic


def merge_panel_gain_ranges(dir_ctype, panel_id, ctype, tstamp, shape, dtype, ofname, fmt='%.3f', fac_mode=0o777):

    logger.debug('In merge_panel_gain_ranges for\n  dir_ctype: %s\n  id: %s\n  ctype=%s tstamp=%s shape=%s dtype=%s fmt=%s'%\
                 (dir_ctype, panel_id, ctype, str(tstamp), str(shape), str(dtype), str(fmt)))

    logger.info('merge ctype: %s\n    in: %s' % (ctype, dir_ctype))

    #dtype = np.uint64 if ctype in ('status', ) else np.float32
    nda_def = np.ones(shape, dtype=dtype) if ctype in ('gain', 'gainci', 'rms', 'pixel_gain', 'pixel_gainci', 'pixel_rms') else\
              np.zeros(shape, dtype=dtype)

    lstnda = []
    for igm,gm in enumerate(ue.GAIN_MODES):
        fname = None if gm in ue.GAIN_MODES[5:] and ctype in ('status', 'rms', 'pixel_status', 'pixel_rms') else\
                find_file_for_timestamp(dir_ctype, '%s-%s' % (ctype,gm), tstamp)
        nda = np.loadtxt(fname, dtype=dtype) if fname is not None else\
              nda_def*GAIN_FACTOR_DEF[igm] if ctype in ('gain', 'gainci', 'pixel_gain', 'pixel_gainci') else\
              nda_def

        # normalize gains for ctype 'gainci'
        if fname is not None and ctype in ('gainci', 'pixel_gainci'):
            med_nda = np.median(nda)
            dir_gain = dir_ctype
            if med_nda != 0:
                f_adu_to_kev = 0

                if gm in GAIN_MODES_IN: # 'FH','FM','FL','AHL_H','AML_M' # 'AHL_L','AML_L'
                    f_adu_to_kev = GAIN_FACTOR_DEF[igm] / med_nda
                    nda = nda * f_adu_to_kev

                elif gm=='AHL_L':
                    gain_hl_h = load_panel_constants(dir_gain, 'gainci-AHL_H', tstamp)
                    if gain_hl_h is None: continue
                    med_hl_h = np.median(gain_hl_h)
                    #V1
                    #ratio_lh = med_nda/med_hl_h if med_hl_h>0 else 0
                    #f_adu_to_kev = ratio_lh * GAIN_FACTOR_DEF[3] / med_nda
                    f_adu_to_kev = GAIN_FACTOR_DEF[3] / med_hl_h if med_hl_h>0 else 0
                    nda *= f_adu_to_kev
                    #V2
                    #nda = GAIN_FACTOR_DEF[3] * divide_protected(nda, gain_hl_h)

                elif gm=='AML_L':
                    gain_ml_m = load_panel_constants(dir_gain, 'gainci-AML_M', tstamp)
                    if gain_ml_m is None: continue
                    med_ml_m = np.median(gain_ml_m)
                    #V1
                    #ratio_lm = med_nda/med_ml_m if med_ml_m>0 else 0
                    #f_adu_to_kev = ratio_lm * GAIN_FACTOR_DEF[4] / med_nda
                    f_adu_to_kev = GAIN_FACTOR_DEF[4] / med_ml_m if med_ml_m>0 else 0
                    nda *= f_adu_to_kev
                    #V2
                    #nda = GAIN_FACTOR_DEF[4] * divide_protected(nda, gain_ml_m)

                    #logger.info('XXXX gm',gm)
                    #logger.info('XXXX med_nda',med_nda)
                    #logger.info('XXXX med_ml_m',med_ml_m)
                    #logger.info('XXXX GAIN_FACTOR_DEF[4]',GAIN_FACTOR_DEF[4])
                    #logger.info('XXXX ratio_lh',ratio_lh)
                    #logger.info('XXXX f_adu_to_kev',f_adu_to_kev)

        lstnda.append(nda if nda is not None else nda_def)
        #logger.debug(info_ndarr(nda, 'nda for %s' % gm))
        #logger.info('%5s : %s' % (gm,fname))

    logger.debug('merge per-gain-range data in segment nda:\n'+'\n'.join([info_ndarr(a,'    ') for a in lstnda]))

    nda = np.stack(tuple(lstnda))
    logger.debug('merge_panel_gain_ranges - merged with shape %s' % str(nda.shape))

    shape_merged = (7, 1) + shape # (7, 1, 352, 384)
    nda.shape = shape_merged
    logger.info(info_ndarr(nda, 'merged: %s' % ctype)\
               +'\n    saved in: %s' % ofname)
    save_ndarray_in_textfile(nda, ofname, fac_mode, fmt)

    nda.shape = shape_merged # (7, 1, 352, 384) because save_ndarray_in_textfile changes shape
    return nda


def add_links_for_gainci_fixed_modes(dir_gain, fnprefix):
    """FH->AHL_H, FM->AML_M, FL->AML_L/AHL_L"""
    logger.debug('in add_links_for_gainci_fixed_modes, prefix: %s' % (fnprefix))
    list_of_files = '\n    '.join([name for name in os.listdir(dir_gain)])
    logger.debug('list_of_files in %s:\n    %s' %(dir_gain, list_of_files))

    dic_links = {'FH': 'AHL_H',
                 'FM': 'AML_M',
                 'FL': 'AML_L'} # 'AHL_L'
    for k,v in dic_links.items():
        fname_auto  = '%s/%s_gainci_%s.dat' % (dir_gain, fnprefix, v)
        fname_fixed = '%s/%s_gainci_%s.dat' % (dir_gain, fnprefix, k)
        #logger.info('file %s existx %s' % (fname_auto, os.path.exists(fname_auto)))
        if os.path.exists(fname_auto) and not os.path.lexists(fname_fixed):
            os.symlink(os.path.abspath(fname_auto), fname_fixed)
    return


def deploy_constants(parser):

    from psana.pscalib.calib.NDArrIO import save_txt; global save_txt
    import psana.pscalib.calib.MDBUtils as mu
    import psana.pscalib.calib.MDBWebUtils as wu
    cc = wu.cc # import psana.pscalib.calib.CalibConstants as cc

    args = parser.parse_args()
    kwa = vars(args)
    repoman = init_repoman_and_logger(parser=parser, **kwa)

    detname    = kwa.get('det', None)
    tstamp     = kwa.get('tstamp', None) # (int) time stamp in format YYYYmmddHHMMSS
    dirrepo    = kwa.get('dirrepo', DIR_REPO_EPIX10KA)
    deploy     = kwa.get('deploy', False)
    fmt_peds   = kwa.get('fmt_peds', '%.3f')
    fmt_gain   = kwa.get('fmt_gain', '%.6f')
    fmt_rms    = kwa.get('fmt_rms',  '%.3f')
    fmt_status = kwa.get('fmt_status', '%4i')
    fmt_min    = kwa.get('fmt_min', '%i')
    fmt_max    = kwa.get('fmt_max', '%i')
    logmode    = kwa.get('logmode', 'DEBUG')
    dirmode    = kwa.get('dirmode',  0o2775)
    filemode   = kwa.get('filemode', 0o664)
    group      = kwa.get('group', 'ps-users')
    high       = kwa.get('high',   16.40) # ADU/keV
    medium     = kwa.get('medium', 5.466) # ADU/keV
    low        = kwa.get('low',    0.164) # ADU/keV
    proc       = kwa.get('proc', 'prsg')
    paninds    = kwa.get('paninds', None)
    version    = kwa.get('version', 'N/A')
    run_beg    = kwa.get('run_beg', None)
    run_end    = kwa.get('run_end', 'end')
    comment    = kwa.get('comment', 'no comment')
    dbsuffix   = kwa.get('dbsuffix', '')

    cpdic = get_config_info_for_dataset_detname(**kwa)
    tstamp_run  = cpdic.get('tstamp',    None) # str
    expnum      = cpdic.get('expnum',    None)
    shape       = cpdic.get('shape',     None)
    strsrc      = cpdic.get('strsrc',    None)
    panel_ids   = cpdic.get('panel_ids', None)
    panel_inds  = cpdic.get('panel_inds',None)
    dettype     = cpdic.get('dettype',   None)
    det_name    = cpdic.get('det_name',  None)
    longname    = cpdic.get('longname',  None)
    shortname   = cpdic.get('shortname', None)
    gains_def   = cpdic.get('gains_def', None)
    irun        = cpdic.get('runnum',    None)
    exp         = cpdic.get('expname',   None)

    repoman.set_dettype(dettype)

    req_inds = None if paninds is None else [int(i) for i in paninds.split(',')] # conv str '0,1,2,3' to list [0,1,2,3]
    logger.info('In %s\n      detector: %s\n      dettype: %s\n      requested_inds: %s'%\
                (SCRNAME, detname, dettype, str(req_inds)))

    assert isinstance(gains_def, tuple)
    assert len(gains_def) == 3

    if high   is None: high   = gains_def[0]
    if medium is None: medium = gains_def[1]
    if low    is None: low    = gains_def[2]

    global GAIN_FACTOR_DEF
    #GAIN_MODES     = ['FH','FM','FL','AHL_H','AML_M','AHL_L','AML_L']
    GAIN_FACTOR_DEF = [high, medium, low, high, medium, low, low]

    CTYPE_FMT = {'pedestals'   : fmt_peds,
                 'pixel_gain'  : fmt_gain,
                 'pixel_rms'   : fmt_rms,
                 'pixel_status': fmt_status,
                 'pixel_min'   : fmt_min,
                 'pixel_max'   : fmt_max}

    CTYPE_DTYPE = cc.dic_calib_name_to_dtype # {'pedestals': np.float32,...}

    logger.info('detector "%s" panel ids:\n  %s' % (detname, '\n  '.join(panel_ids)))

    #if tstamp is None: tstamp = tstamp_run
    _tstamp = tstamp_run

    logger.info('search for calibration files with tstamp <= %s' % _tstamp)

    # dict_consts for constants octype: 'pixel_gain', 'pedestals', etc.
    dic_consts = {}
    for ind, panel_id in zip(panel_inds,panel_ids):

        if req_inds is not None and not (ind in req_inds): continue # skip non-selected panels

        logger.info('%s\nmerge constants for panel:%02d id: %s' % (98*'_', ind, panel_id))

        dir_panel, dir_offset, dir_peds, dir_plots, dir_work, dir_gain, dir_rms, dir_status, dir_min, dir_max = dir_names(repoman, panel_id)

        fnprefix = fname_prefix(shortname, ind, _tstamp, exp, irun, dirname=None) # <dirname>/jungfrauemu_000001-s00-20250203095124-mfxdaq23-r0007
        prefix_offset, prefix_peds, prefix_plots, prefix_gain, prefix_rms, prefix_status, prefix_min, prefix_max =\
            path_prefixes(fnprefix, dir_offset, dir_peds, dir_plots, dir_gain, dir_rms, dir_status, dir_min, dir_max)

        #mpars = (('pedestals', 'pedestals',    prefix_peds,   dir_peds),\
        #         ('rms',       'pixel_rms',    prefix_rms,    dir_rms),\
        #         ('status',    'pixel_status', prefix_status, dir_status),\
        #         ('gain',      'pixel_gain',   prefix_gain,   dir_gain))

        mpars = []
        if 'p' in proc: mpars.append(('pedestals',    'pedestals',    prefix_peds,   dir_peds))
        if 'r' in proc: mpars.append(('pixel_rms',    'pixel_rms',    prefix_rms,    dir_rms))
        if 's' in proc: mpars.append(('pixel_status', 'pixel_status', prefix_status, dir_status))
        if 'g' in proc: mpars.append(('pixel_gain',   'pixel_gain',   prefix_gain,   dir_gain))
        if 'c' in proc: mpars.append(('pixel_gainci', 'pixel_gain',   prefix_gain,   dir_gain))
        if 'm' in proc: mpars.append(('pixel_min',    'pixel_min',    prefix_min,    dir_min))
        if 'x' in proc: mpars.append(('pixel_max',    'pixel_max',    prefix_max,    dir_max))
        if 'c' in proc:
             add_links_for_gainci_fixed_modes(dir_gain, fnprefix) # FH->AHL_H, FM->AML_M, FL->AML_L/AHL_L

        for (ctype, octype, prefix, dir_ctype) in mpars:
            fmt = CTYPE_FMT.get(octype,'%.5f')
            nda_dtype = CTYPE_DTYPE.get(octype, np.float32)

            logger.debug('begin merging for ctype:%s, octype:%s, fmt:%s,\n  prefix:%s' % (ctype, octype, fmt, prefix))
            fname = '%s-%s.txt' % (prefix, ctype)

            nda = merge_panel_gain_ranges(dir_ctype, panel_id, ctype, _tstamp, shape, nda_dtype, fname, fmt, filemode)
            if octype in dic_consts: dic_consts[octype].append(nda) # append for panel per ctype
            else:                    dic_consts[octype] = [nda,]

    logger.info('\n%s\nMERGE PANEL CONSTANTS AND DEPLOY THEM\n' % (80*'_'))

    #if deploy:

    #dmerge = dir_merge(dirrepo)
    dmerge = repoman.dir_merge()

    create_directory(dmerge, mode=dirmode)
    fmerge_prefix = fname_prefix_merge(dmerge, shortname, _tstamp, exp, irun)

    for octype, lst in dic_consts.items():
        mrg_nda = merge_panels(lst)
        logger.info(info_ndarr(mrg_nda, 'merged constants for %s ' % octype))
        fmerge = '%s-%s.txt' % (fmerge_prefix, octype)
        fmt = CTYPE_FMT.get(octype,'%.5f')
        save_ndarray_in_textfile(mrg_nda, fmerge, filemode, fmt)

        if True: # deploy:

#          # check opt "-t" if constants need to be deployed with diffiernt time stamp or run number
#          use_external_run = tstamp is not None and tstamp<10000
#          use_external_ts  = tstamp is not None and tstamp>9999
#          tvalid_sec = time_sec_from_stamp(fmt=cc.TSFORMAT_SHORT, time_stamp=str(tstamp))\
#                  if use_external_ts else cpdic.get('trun_sec', None)
#          ivalid_run = tstamp if use_external_run else irun\
#                  if not use_external_ts else 0

          tvalid_sec = time_sec_from_stamp(fmt=cc.TSFORMAT_SHORT, time_stamp=str(tstamp))\
                       if tstamp is not None else cpdic.get('trun_sec', None)
          ivalid_run = irun if run_beg is None else run_beg

          dtype = 'ndarray'

          kwa = {
            'iofname'    : fmerge,
            'experiment' : exp,
            'ctype'      : octype,
            'dtype'      : dtype,
            'detector'   : shortname,
            'shortname'  : shortname,
            'detname'    : det_name,
            'longname'   : longname,
            'time_sec'   : tvalid_sec,
            'time_stamp' : str_tstamp(fmt=cc.TSFORMAT, time_sec=int(tvalid_sec)),
            'tsshort'    : str_tstamp(fmt=cc.TSFORMAT_SHORT, time_sec=int(tvalid_sec)),
            'tstamp_orig': cpdic.get('tsrun_dark', None),
            'run'        : ivalid_run,
            'run_beg'    : run_beg,
            'run_end'    : run_end,
            'run_orig'   : irun,
            'version'    : version,
            'comment'    : comment,
            'extpars'    : {'content':'extended parameters dict->json->str',},
            'dettype'    : dettype,
            'dbsuffix'   : dbsuffix
          }
          d = dict_filter(kwa, list_keys=('experiment', 'detname', 'detector', 'shortname', 'ctype',\
                                          'run', 'run_orig', 'run_beg', 'run_end', 'time_stamp', 'tstamp_orig', 'dettype', 'iofname', 'version'))
          logger.info('partial metadata:\n  %s' % '\n  '.join(['%16s: %s' %(k,v) for k,v in d.items()]))

          data = mu.data_from_file(fmerge, octype, dtype, True)
          logger.debug(info_ndarr(data, 'merged constants loaded from file'))

          if deploy:
            resp = wu.deploy_constants(data, exp, longname, url=cc.URL_KRB, krbheaders=cc.KRBHEADERS, **kwa)
            #id_data_exp, id_data_det, id_doc_exp, id_doc_det = resp if resp is not None

          else:
            logger.warning('TO DEPLOY CONSTANTS ADD OPTION -D')

    repoman.logfile_save()


if __name__ == "__main__":

  def test_pedestals_calibration_epix10ka(tname):
    print("""DEPRECATED - use script epix10ka_pedestals_calibration""")

  def test_offset_calibration_epix10ka(tname):
    print('N/A')

  def test_deploy_constants_epix10ka(tname):
    print("""DEPRECATED - use script epix10ka_deploy_constants""")

  USAGE = 'DEPRECATED: python %s <test-name>' % SCRNAME\
        + '\n  where <test-name>'\
        + '\n  1: test_offset_calibration_epix10ka - TBD'\
        + '\n  2: test_pedestals_calibration_epix10ka'\
        + '\n  3: test_deploy_constants_epix10ka - TBD'\
        + '\n'

if __name__ == "__main__":
    print(80*'_')
    logging.basicConfig(format='[%(levelname).1s] L%(lineno)04d: %(message)s', level=logging.DEBUG)
    tname = sys.argv[1] if len(sys.argv)>1 else '0'
    if   tname == '1': test_offset_calibration_epix10ka(tname)
    elif tname == '2': test_pedestals_calibration_epix10ka(tname)
    elif tname == '3': test_deploy_constants_epix10ka(tname)
    else:
        print('Usage: %s'%USAGE)
        sys.exit('Not recognized test name: "%s"' % tname)
    sys.exit('End of %s' % sys.argv[0])

# EOF
